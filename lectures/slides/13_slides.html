

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lecture 13: Feature engineering and feature selection &#8212; CPSC 330 Applied Machine Learning 2023W1</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/slides/13_slides';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/UBC-CS-logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/UBC-CS-logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Things you should know</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/README.html">CPSC 330 Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../learning-objectives.html">Course Learning Objectives</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01_intro.html">Lecture 1: Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_decision-trees.html">Lecture 2: Terminology, Baselines, Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_ml-fundamentals.html">Lecture 3: Machine Learning Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_kNNs-SVM-RBF.html">Lecture 4: <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours and SVM RBFs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_preprocessing-pipelines.html">Lecture 5: Preprocessing and <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_column-transformer-text-feats.html">Lecture 6: <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> <code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code> and Text Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_linear-models.html">Lecture 7: Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08_hyperparameter-optimization.html">Lecture 8: Hyperparameter Optimization and Optimization Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09_classification-metrics.html">Lecture 9: Classification metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10_regression-metrics.html">Lecture 10: Regression metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_ensembles.html">Lecture 11: Ensembles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12_feat-importances.html">Lecture 12: Feature importances and model transparency</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13_feature-engineering-selection.html">Lecture 13: Feature engineering and feature selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../14_K-Means.html">Lecture 14: K-Means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15_DBSCAN-hierarchical.html">Lecture 15: More Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../16_recommender-systems.html">Lecture 16: Recommender Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../17_natural-language-processing.html">Lecture 17: Introduction to natural language processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../18_intro_to_computer-vision.html">Lecture 18: Multi-class classification and introduction to computer vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../19_time-series.html">Lecture 19: Time series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20_survival-analysis.html">Lecture 20: Survival analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21_communication.html">Lecture 21: Communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23_deployment-conclusion.html">Lecture 23: Deployment and conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../final-review.html">Final review guiding questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../A-Quick-intro-to-LLMs.html">Bonus: A high-level quick introduction to LLMs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Demos</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../class_demos/03_class-demo.html">Lecture 3: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../class_demos/04_class-demo.html">Lecture 4: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../class_demos/05-06_class-demo.html">Lectures 5 and 6: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../class_demos/07_class-demo.html">Lectures 7: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../class_demos/09_class-demo.html">Exploring classification metrics</a></li>

<li class="toctree-l1"><a class="reference internal" href="../class_demos/14_class-demo.html">Lecture 14: Class demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../class_demos/15_class-demo.html">Lecture 15: Class demo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../AppendixA.html">Appendix A: Common features used in text classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../AppendixB.html">Appendix B: K-Means customer segmentation case study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../AppendixC.html">Appendix C: Representing documents using embeddings</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../attribution.html">Attributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../LICENSE.html">LICENSE</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/lectures/slides/13_slides.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 13: Feature engineering and feature selection</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#announcements">Announcements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">Learning outcomes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering-motivation">Feature engineering: Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iclicker-exercise-13-1">iClicker Exercise 13.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#garbage-in-garbage-out">Garbage in, garbage out.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activity-how-can-you-measure-quality-of-the-data-3-mins">Activity: How can you measure quality of the data? (~3 mins)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-feature-engineering">What is feature engineering?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-quotes-on-feature-engineering">Some quotes on feature engineering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#better-features-usually-help-more-than-a-better-model">Better features usually help more than a better model.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-best-features-may-be-dependent-on-the-model-you-use">The best features may be dependent on the model you use.</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#domain-specific-transformations">Domain-specific transformations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Domain-specific transformations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-and-feature-crosses">Feature interactions and feature crosses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-crosses-for-one-hot-encoded-features">Feature crosses for one-hot encoded features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-of-feature-engineering-with-numeric-features">Demo of feature engineering with numeric features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-of-feature-engineering-for-text-data">Demo of feature engineering for text data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baseline">Baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bag-of-words-model">Bag-of-words model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-it-possible-to-further-improve-the-scores">Is it possible to further improve the scores?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spacy">spaCy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-from-a-project">An example from a project</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-feature-engineering-for-our-problem">Simple feature engineering for our problem.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interim-summary">Interim summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering">Feature engineering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection-introduction-and-motivation">Feature selection: Introduction and motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-feature-selection">What is feature selection?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-feature-selection">Why feature selection?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-carry-out-feature-selection">How do we carry out feature selection?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-models-recap">Linear models recap</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression-l2-penalty">Ridge regression (L2 penalty)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-regression-l1-penalty">Lasso regression (L1 penalty)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-l1-and-l2">Logistic regression (L1 and L2)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#l1-vs-l2-penalty-summary">L1 vs L2 penalty summary</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-selection">Model-based selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iclicker-exercise-13-2">(iClicker) Exercise 13.2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recursive-feature-elimination-rfe">Recursive feature elimination (RFE)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rfe-algorithm">RFE algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-search-and-score">(Optional) Search and score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-idea-of-search-and-score-methods">General idea of search and score methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-forward-or-backward-selection">(Optional) Forward or backward selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-ways-to-search">Other ways to search</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warnings-about-feature-selection">Warnings about feature selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iclicker-exercise-13-3">(iClicker) Exercise 13.3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-problems-with-feature-selection">(Optional) Problems with feature selection</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-is-relevance-clearly-defined">Example: Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#is-relevance-clearly-defined">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Warnings about feature selection</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-resources">Relevant resources</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.random</span> <span class="k">as</span> <span class="nn">npr</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sb</span>

<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ColumnTransformer</span><span class="p">,</span>
    <span class="n">TransformedTargetRegressor</span><span class="p">,</span>
    <span class="n">make_column_transformer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">RidgeCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">OrdinalEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_std_cross_val_scores</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns mean and std of cross validation</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model :</span>
<span class="sd">        scikit-learn model</span>
<span class="sd">    X_train : numpy array or pandas DataFrame</span>
<span class="sd">        X in the training data</span>
<span class="sd">    y_train :</span>
<span class="sd">        y in the training data</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">        pandas Series with mean scores from cross_validation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">mean_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">std_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">out_col</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mean_scores</span><span class="p">)):</span>
        <span class="n">out_col</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="sa">f</span><span class="s2">&quot;%0.3f (+/- %0.3f)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean_scores</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">std_scores</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">out_col</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">mean_scores</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="lecture-13-feature-engineering-and-feature-selection">
<h1>Lecture 13: Feature engineering and feature selection<a class="headerlink" href="#lecture-13-feature-engineering-and-feature-selection" title="Permalink to this heading">#</a></h1>
<p>UBC 2023-24</p>
<p>Instructor: Varada Kolhatkar and Andrew Roth</p>
<section id="announcements">
<h2>Announcements<a class="headerlink" href="#announcements" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Midterm is next week.</p>
<ul>
<li><p>Bring your laptop. Make sure that it’s fully charged.</p></li>
<li><p>Bring your UBC ID Card.</p></li>
</ul>
</li>
<li><p>HW5 is available.</p></li>
</ul>
</section>
<section id="learning-outcomes">
<h2>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this heading">#</a></h2>
<p>From this lecture, students are expected to be able to:</p>
<ul class="simple">
<li><p>Explain what feature engineering is and the importance of feature engineering in building machine learning models.  - Carry out preliminary feature engineering on numeric and text data.</p></li>
<li><p>Explain the general concept of feature selection.</p></li>
<li><p>Discuss and compare different feature selection methods at a high level.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s implementation of model-based selection and recursive feature elimination (<code class="docutils literal notranslate"><span class="pre">RFE</span></code>)</p></li>
</ul>
</section>
<section id="feature-engineering-motivation">
<h2>Feature engineering: Motivation<a class="headerlink" href="#feature-engineering-motivation" title="Permalink to this heading">#</a></h2>
<section id="iclicker-exercise-13-1">
<h3>iClicker Exercise 13.1<a class="headerlink" href="#iclicker-exercise-13-1" title="Permalink to this heading">#</a></h3>
<p><strong>iClicker cloud join link: https://join.iclicker.com/SNBF</strong></p>
<p><strong>Select the most accurate option below.</strong></p>
<p>Suppose you are working on a machine learning project. If you have to prioritize one of the following in your project which of the following would it be?</p>
<ul class="simple">
<li><p>(A) The quality and size of the data</p></li>
<li><p>(B) Most recent deep neural network model</p></li>
<li><p>(C) Most recent optimization algorithm</p></li>
<li><p>(D) Domain expertise</p></li>
</ul>
<p><strong>Discussion question</strong></p>
<ul class="simple">
<li><p>Suppose we want to predict whether a flight will arrive on time or be delayed. We have a dataset with the following information about flights:</p>
<ul>
<li><p>Departure Time</p></li>
<li><p>Expected Duration of Flight (in minutes)</p></li>
</ul>
</li>
</ul>
<p>Upon analyzing the data, you notice a pattern: flights tend to be delayed more often during the evening rush hours. What feature could be valuable to add for this prediction task?
<br><br><br><br></p>
</section>
<section id="garbage-in-garbage-out">
<h3>Garbage in, garbage out.<a class="headerlink" href="#garbage-in-garbage-out" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Model building is interesting. But in your machine learning projects, you’ll be spending more than half of your time on data preparation, feature engineering, and transformations.</p></li>
<li><p>The <em>quality</em> of the data is important. Your model is only as good as your data.</p></li>
</ul>
</section>
<section id="activity-how-can-you-measure-quality-of-the-data-3-mins">
<h3>Activity: How can you measure quality of the data? (~3 mins)<a class="headerlink" href="#activity-how-can-you-measure-quality-of-the-data-3-mins" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Write some attributes of good- and bad-quality data in
<a class="reference external" href="https://docs.google.com/document/d/1uRBW0woUJ4KYo-feChK4F6hmjKA7HywYmaYdOe9la60/edit?usp=sharing">this Google Document</a>.</p></li>
</ul>
</section>
<section id="what-is-feature-engineering">
<h3>What is feature engineering?<a class="headerlink" href="#what-is-feature-engineering" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Better features: more flexibility, higher score, we can get by with simple and more interpretable models.</p></li>
<li><p>If your features, i.e., representation is bad, whatever fancier model you build is not going to help.</p></li>
</ul>
<blockquote>
<b>Feature engineering</b> is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.<br> 
- Jason Brownlee    
</blockquote>    </section>
<section id="some-quotes-on-feature-engineering">
<h3>Some quotes on feature engineering<a class="headerlink" href="#some-quotes-on-feature-engineering" title="Permalink to this heading">#</a></h3>
<p>A quote by Pedro Domingos <a class="reference external" href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf">A Few Useful Things to Know About Machine Learning</a></p>
<blockquote>
... At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used. 
</blockquote>
<p>A quote by Andrew Ng, <a class="reference external" href="https://ai.stanford.edu/~ang/slides/DeepLearning-Mar2013.pptx">Machine Learning and AI via Brain simulations</a></p>
<blockquote>
Coming up with features is difficult, time-consuming, requires expert knowledge. "Applied machine learning" is basically feature engineering.
</blockquote></section>
<section id="better-features-usually-help-more-than-a-better-model">
<h3>Better features usually help more than a better model.<a class="headerlink" href="#better-features-usually-help-more-than-a-better-model" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Good features would ideally:</p>
<ul>
<li><p>capture most important aspects of the problem</p></li>
<li><p>allow learning with few examples</p></li>
<li><p>generalize to new scenarios.</p></li>
</ul>
</li>
<li><p>There is a trade-off between simple and expressive features:</p>
<ul>
<li><p>With simple features overfitting risk is low, but scores might be low.</p></li>
<li><p>With complicated features scores can be high, but so is overfitting risk.</p></li>
</ul>
</li>
</ul>
</section>
<section id="the-best-features-may-be-dependent-on-the-model-you-use">
<h3>The best features may be dependent on the model you use.<a class="headerlink" href="#the-best-features-may-be-dependent-on-the-model-you-use" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Examples:</p>
<ul>
<li><p>For counting-based methods like decision trees separate relevant groups of variable values</p>
<ul>
<li><p>Discretization makes sense</p></li>
</ul>
</li>
<li><p>For distance-based methods like KNN, we want different class labels to be “far”.</p>
<ul>
<li><p>Standardization</p></li>
</ul>
</li>
<li><p>For regression-based methods like linear regression, we want targets to have a linear dependency on features.</p></li>
</ul>
</li>
</ul>
<section id="domain-specific-transformations">
<h4>Domain-specific transformations<a class="headerlink" href="#domain-specific-transformations" title="Permalink to this heading">#</a></h4>
<p>In some domains there are natural transformations to do:</p>
<ul class="simple">
<li><p>Spectrograms (sound data)</p></li>
<li><p>Wavelets (image data)</p></li>
<li><p>Convolutions</p></li>
<li><p>Read counts (genomics)</p></li>
</ul>
<p><img alt="" src="../../_images/spectogram.png" /></p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Spectrogram">Source</a></p>
</section>
<section id="id1">
<h4>Domain-specific transformations<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<p><img alt="" src="../../_images/genomics_snv_counts.svg" /></p>
</section>
</section>
<section id="feature-interactions-and-feature-crosses">
<h3>Feature interactions and feature crosses<a class="headerlink" href="#feature-interactions-and-feature-crosses" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A <strong>feature cross</strong> is a synthetic feature formed by multiplying or crossing two or more features.</p></li>
<li><p>Example:
Is the following dataset (XOR function) linearly separable?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1</td>
      <td>-1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sb</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;X1&#39;, ylabel=&#39;X2&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/68b68936efadc3206eea0f99c5ec49be67950355db35d43cfccc867e64b7b4ab.png" src="../../_images/68b68936efadc3206eea0f99c5ec49be67950355db35d43cfccc867e64b7b4ab.png" />
</div>
</div>
<ul class="simple">
<li><p>For XOR like problems, if we create a feature cross <span class="math notranslate nohighlight">\(x1x2\)</span>, the data becomes linearly separable.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;X1X2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;X2&quot;</span><span class="p">]</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1</th>
      <th>X2</th>
      <th>target</th>
      <th>X1X2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1</td>
      <td>-1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1</td>
      <td>1</td>
      <td>0</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sb</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;X1X2&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;X2&#39;, ylabel=&#39;X1X2&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/e70c382a44d3cb2338bafe5255064907d531371d4b040467589db9a2f525c977.png" src="../../_images/e70c382a44d3cb2338bafe5255064907d531371d4b040467589db9a2f525c977.png" />
</div>
</div>
<p>Let’s look at an example with more data points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># xx, yy = np.meshgrid(np.linspace(-3, 3, 50), np.linspace(-3, 3, 50))</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">sb</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&quot;X1&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;X2&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: xlabel=&#39;X1&#39;, ylabel=&#39;X2&#39;&gt;
</pre></div>
</div>
<img alt="../../_images/09b578210d1eb5fc81c7bc8f8537e9e9861ca17bb2ad7bdc6da242f84f722654.png" src="../../_images/09b578210d1eb5fc81c7bc8f8537e9e9861ca17bb2ad7bdc6da242f84f722654.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.535
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">pipe_xor</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">pipe_xor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.995
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">pipe_xor</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;polynomialfeatures&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">pipe_xor</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logisticregression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Feature coefficient&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>-0.001828</td>
    </tr>
    <tr>
      <th>x0</th>
      <td>-0.028418</td>
    </tr>
    <tr>
      <th>x1</th>
      <td>0.130472</td>
    </tr>
    <tr>
      <th>x0 x1</th>
      <td>-5.085936</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The interaction feature has the biggest coefficient!</p>
</section>
<section id="feature-crosses-for-one-hot-encoded-features">
<h3>Feature crosses for one-hot encoded features<a class="headerlink" href="#feature-crosses-for-one-hot-encoded-features" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>You can think of feature crosses of one-hot-features as logical conjunctions</p></li>
<li><p>Suppose you want to predict whether you will find parking or not based on two features:</p>
<ul>
<li><p>area (possible categories: UBC campus and Rogers Arena)</p></li>
<li><p>time of the day (possible categories: 9am and 7pm)</p></li>
</ul>
</li>
<li><p>A feature cross in this case would create four new features:</p>
<ul>
<li><p>UBC campus and 9am</p></li>
<li><p>UBC campus and 7pm</p></li>
<li><p>Rogers Arena and 9am</p></li>
<li><p>Rogers Arena and 7pm.</p></li>
</ul>
</li>
<li><p>The features UBC campus and 9am on their own are not that informative but the newly created feature UBC campus and 9am or Rogers Arena and 7pm would be quite informative.</p></li>
</ul>
<ul class="simple">
<li><p>Coming up with the right combination of features requires some domain knowledge or careful examination of the data.</p></li>
<li><p>There is no easy way to support feature crosses in sklearn.</p></li>
</ul>
</section>
<section id="demo-of-feature-engineering-with-numeric-features">
<h3>Demo of feature engineering with numeric features<a class="headerlink" href="#demo-of-feature-engineering-with-numeric-features" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Remember the <a class="reference external" href="https://www.kaggle.com/datasets/camnugent/california-housing-prices">California housing dataset</a> we used earlier in the course?</p></li>
<li><p>The prediction task is predicting <code class="docutils literal notranslate"><span class="pre">median_house_value</span></code> for a given property.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">housing_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/california_housing.csv&quot;</span><span class="p">)</span>
<span class="n">housing_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">housing_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20433 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object 
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</pre></div>
</div>
</div>
</div>
<p>Suppose we decide to train <code class="docutils literal notranslate"><span class="pre">ridge</span></code> model on this dataset.</p>
<ul class="simple">
<li><p>What would happen if you train a model without applying any transformation on the categorical features ocean_proximity?</p>
<ul>
<li><p>Error!! A linear model requires all features in a numeric form.</p></li>
</ul>
</li>
<li><p>What would happen if we apply OHE on <code class="docutils literal notranslate"><span class="pre">ocean_proximity</span></code> but we do not scale the features?</p>
<ul>
<li><p>No syntax error. But the model results are likely to be poor.</p></li>
</ul>
</li>
<li><p>Do we need to apply any other transformations on this data?</p></li>
</ul>
<p>In this section, we will look into some common ways to do feature engineering for numeric or categorical features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">housing_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have total rooms and the number of households in the neighbourhood. How about creating rooms_per_household feature using this information?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">rooms_per_household</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">rooms_per_household</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;total_rooms&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;households&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
      <th>rooms_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>9950</th>
      <td>-122.33</td>
      <td>38.38</td>
      <td>28.0</td>
      <td>1020.0</td>
      <td>169.0</td>
      <td>504.0</td>
      <td>164.0</td>
      <td>4.5694</td>
      <td>287500.0</td>
      <td>INLAND</td>
      <td>6.219512</td>
    </tr>
    <tr>
      <th>3547</th>
      <td>-118.60</td>
      <td>34.26</td>
      <td>18.0</td>
      <td>6154.0</td>
      <td>1070.0</td>
      <td>3010.0</td>
      <td>1034.0</td>
      <td>5.6392</td>
      <td>271500.0</td>
      <td>&lt;1H OCEAN</td>
      <td>5.951644</td>
    </tr>
    <tr>
      <th>4448</th>
      <td>-118.21</td>
      <td>34.07</td>
      <td>47.0</td>
      <td>1346.0</td>
      <td>383.0</td>
      <td>1452.0</td>
      <td>371.0</td>
      <td>1.7292</td>
      <td>191700.0</td>
      <td>&lt;1H OCEAN</td>
      <td>3.628032</td>
    </tr>
    <tr>
      <th>6984</th>
      <td>-118.02</td>
      <td>33.96</td>
      <td>36.0</td>
      <td>2071.0</td>
      <td>398.0</td>
      <td>988.0</td>
      <td>404.0</td>
      <td>4.6226</td>
      <td>219700.0</td>
      <td>&lt;1H OCEAN</td>
      <td>5.126238</td>
    </tr>
    <tr>
      <th>4432</th>
      <td>-118.20</td>
      <td>34.08</td>
      <td>49.0</td>
      <td>1320.0</td>
      <td>309.0</td>
      <td>1405.0</td>
      <td>328.0</td>
      <td>2.4375</td>
      <td>114000.0</td>
      <td>&lt;1H OCEAN</td>
      <td>4.024390</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s start simple. Imagine that we only three features: <code class="docutils literal notranslate"><span class="pre">longitude</span></code>, <code class="docutils literal notranslate"><span class="pre">latitude</span></code>, and our newly created <code class="docutils literal notranslate"><span class="pre">rooms_per_household</span></code> feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_housing</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span> <span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="s2">&quot;rooms_per_household&quot;</span><span class="p">]]</span>
<span class="n">y_train_housing</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;median_house_value&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>

<span class="n">numeric_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span> <span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="s2">&quot;rooms_per_household&quot;</span><span class="p">]</span>

<span class="n">preprocessor1</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">()),</span> <span class="n">numeric_feats</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_1</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor1</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">lr_1</span><span class="p">,</span> <span class="n">X_train_housing</span><span class="p">,</span> <span class="n">y_train_housing</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.003925</td>
      <td>0.001269</td>
      <td>0.280028</td>
      <td>0.311769</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.003150</td>
      <td>0.001174</td>
      <td>0.325319</td>
      <td>0.300464</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.003116</td>
      <td>0.001156</td>
      <td>0.317277</td>
      <td>0.301952</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.003103</td>
      <td>0.001153</td>
      <td>0.316798</td>
      <td>0.303004</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.003081</td>
      <td>0.001141</td>
      <td>0.260258</td>
      <td>0.314840</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>The scores are not great.</p></li>
<li><p>Let’s look at the distribution of the longitude and latitude features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;longitude&quot;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of latitude feature&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/25671743a39c7d33ee22cc5bd2af5dcdafa915ca626987ca995cfd52be9aee96.png" src="../../_images/25671743a39c7d33ee22cc5bd2af5dcdafa915ca626987ca995cfd52be9aee96.png" />
</div>
</div>
<ul class="simple">
<li><p>Suppose you are planning to build a linear model for housing price prediction.</p></li>
<li><p>If we think longitude is a good feature for prediction, does it makes sense to use the floating point representation of this feature that’s given to us?</p></li>
<li><p>Remember that linear models can capture only linear relationships.</p></li>
</ul>
<ul class="simple">
<li><p>How about discretizing latitude and longitude features and putting them into buckets?</p></li>
<li><p>This process of transforming numeric features into categorical features is called bucketing or binning.</p></li>
<li><p>In <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> you can do this using <code class="docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code> transformer.</p></li>
<li><p>Let’s examine whether we get better results with binning.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="n">discretization_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span> <span class="s2">&quot;longitude&quot;</span><span class="p">]</span>
<span class="n">numeric_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rooms_per_household&quot;</span><span class="p">]</span>

<span class="n">preprocessor2</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s2">&quot;onehot&quot;</span><span class="p">),</span> <span class="n">discretization_feats</span><span class="p">),</span>
    <span class="p">(</span><span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">()),</span> <span class="n">numeric_feats</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_2</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor2</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">lr_2</span><span class="p">,</span> <span class="n">X_train_housing</span><span class="p">,</span> <span class="n">y_train_housing</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.021124</td>
      <td>0.003546</td>
      <td>0.441445</td>
      <td>0.456419</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.015661</td>
      <td>0.005281</td>
      <td>0.469571</td>
      <td>0.446216</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.015863</td>
      <td>0.003311</td>
      <td>0.479132</td>
      <td>0.446869</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.016597</td>
      <td>0.003249</td>
      <td>0.450822</td>
      <td>0.453367</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.015598</td>
      <td>0.003334</td>
      <td>0.388169</td>
      <td>0.467628</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The results are better with binned features. Let’s examine how do these binned features look like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">preprocessor2</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_housing</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">(),</span>
    <span class="n">columns</span><span class="o">=</span><span class="n">preprocessor2</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>kbinsdiscretizer__latitude_0.0</th>
      <th>kbinsdiscretizer__latitude_1.0</th>
      <th>kbinsdiscretizer__latitude_2.0</th>
      <th>kbinsdiscretizer__latitude_3.0</th>
      <th>kbinsdiscretizer__latitude_4.0</th>
      <th>kbinsdiscretizer__latitude_5.0</th>
      <th>kbinsdiscretizer__latitude_6.0</th>
      <th>kbinsdiscretizer__latitude_7.0</th>
      <th>kbinsdiscretizer__latitude_8.0</th>
      <th>kbinsdiscretizer__latitude_9.0</th>
      <th>...</th>
      <th>kbinsdiscretizer__longitude_11.0</th>
      <th>kbinsdiscretizer__longitude_12.0</th>
      <th>kbinsdiscretizer__longitude_13.0</th>
      <th>kbinsdiscretizer__longitude_14.0</th>
      <th>kbinsdiscretizer__longitude_15.0</th>
      <th>kbinsdiscretizer__longitude_16.0</th>
      <th>kbinsdiscretizer__longitude_17.0</th>
      <th>kbinsdiscretizer__longitude_18.0</th>
      <th>kbinsdiscretizer__longitude_19.0</th>
      <th>pipeline__rooms_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.316164</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.209903</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-0.711852</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-0.117528</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-0.554621</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>16507</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.064307</td>
    </tr>
    <tr>
      <th>16508</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.235706</td>
    </tr>
    <tr>
      <th>16509</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.212581</td>
    </tr>
    <tr>
      <th>16510</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-0.271037</td>
    </tr>
    <tr>
      <th>16511</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.027321</td>
    </tr>
  </tbody>
</table>
<p>16512 rows × 41 columns</p>
</div></div></div>
</div>
<p>How about discretizing all three features?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="n">discretization_feats</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latitude&quot;</span><span class="p">,</span> <span class="s2">&quot;longitude&quot;</span><span class="p">,</span> <span class="s2">&quot;rooms_per_household&quot;</span><span class="p">]</span>

<span class="n">preprocessor3</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s2">&quot;onehot&quot;</span><span class="p">),</span> <span class="n">discretization_feats</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_3</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor3</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">())</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">lr_3</span><span class="p">,</span> <span class="n">X_train_housing</span><span class="p">,</span> <span class="n">y_train_housing</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.014727</td>
      <td>0.002532</td>
      <td>0.590618</td>
      <td>0.571969</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.014059</td>
      <td>0.002456</td>
      <td>0.575907</td>
      <td>0.570473</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.013775</td>
      <td>0.002420</td>
      <td>0.579091</td>
      <td>0.573542</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.015736</td>
      <td>0.002495</td>
      <td>0.571500</td>
      <td>0.574260</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.013764</td>
      <td>0.002423</td>
      <td>0.541488</td>
      <td>0.581687</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>The results have improved further!!</p></li>
<li><p>Let’s examine the coefficients</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_housing</span><span class="p">,</span> <span class="n">y_train_housing</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">lr_3</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;columntransformer&quot;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s2">&quot;kbinsdiscretizer&quot;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">lr_3</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;ridge&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span>
    <span class="n">index</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;coefficient&quot;</span><span class="p">],</span>
<span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;coefficient&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">coefs_df</span><span class="o">.</span><span class="n">head</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;bound method NDFrame.head of                             coefficient
longitude_1.0             211343.036136
latitude_1.0              205059.296601
latitude_0.0              201862.534342
longitude_0.0             190319.721818
longitude_2.0             160282.191204
longitude_3.0             157234.920305
latitude_2.0              154105.963689
rooms_per_household_19.0  138503.477291
latitude_8.0              135299.516394
longitude_4.0             132292.924485
latitude_7.0              124982.236174
latitude_3.0              118563.786115
longitude_5.0             116145.526596
rooms_per_household_18.0  102044.252042
longitude_6.0              96554.525554
latitude_4.0               92809.389349
latitude_6.0               90982.951669
latitude_9.0               71096.652487
rooms_per_household_17.0   70472.564483
latitude_5.0               69411.023366
longitude_10.0             52398.892961
rooms_per_household_16.0   44311.362553
rooms_per_household_15.0   31454.877046
longitude_7.0              25658.862997
latitude_10.0              20311.784573
rooms_per_household_14.0   16460.273962
rooms_per_household_13.0    9351.210272
longitude_8.0               6322.652986
rooms_per_household_12.0    1858.970683
rooms_per_household_11.0  -12178.614567
longitude_9.0             -14579.657675
rooms_per_household_10.0  -16630.535622
rooms_per_household_9.0   -19591.810098
longitude_11.0            -22741.635200
rooms_per_household_8.0   -26919.381190
rooms_per_household_7.0   -30573.540359
rooms_per_household_6.0   -32734.570739
rooms_per_household_4.0   -40689.197649
rooms_per_household_3.0   -42060.071975
rooms_per_household_5.0   -43445.134061
rooms_per_household_2.0   -47606.596151
rooms_per_household_0.0   -50884.444297
rooms_per_household_1.0   -51143.091625
latitude_13.0             -57510.779271
longitude_14.0            -70978.802502
longitude_13.0            -89270.957075
longitude_12.0            -90669.093228
latitude_11.0            -100275.316426
longitude_15.0           -105080.071654
latitude_12.0            -111438.823543
latitude_14.0            -114836.305674
latitude_15.0            -116443.256437
longitude_16.0           -119570.316230
latitude_16.0            -140185.299164
longitude_17.0           -174766.515848
latitude_18.0            -185868.754874
latitude_17.0            -195564.951574
longitude_18.0           -205144.956966
longitude_19.0           -255751.248664
latitude_19.0            -262361.647795&gt;
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Does it make sense to take feature crosses in this context?</p></li>
<li><p>What information would they encode?</p></li>
</ul>
</section>
<section id="demo-of-feature-engineering-for-text-data">
<h3>Demo of feature engineering for text data<a class="headerlink" href="#demo-of-feature-engineering-for-text-data" title="Permalink to this heading">#</a></h3>
<p>We will be using <a class="reference external" href="https://www.kaggle.com/code/kerneler/starter-covid-19-nlp-text-d3a3baa6-e/data">Covid tweets</a> dataset for this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/Corona_NLP_test.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Negative              1041
Positive               947
Neutral                619
Extremely Positive     599
Extremely Negative     592
Name: Sentiment, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserName</th>
      <th>ScreenName</th>
      <th>Location</th>
      <th>TweetAt</th>
      <th>OriginalTweet</th>
      <th>Sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1927</th>
      <td>1928</td>
      <td>46880</td>
      <td>Seattle, WA</td>
      <td>13-03-2020</td>
      <td>While I don't like all of Amazon's choices, to...</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>1068</th>
      <td>1069</td>
      <td>46021</td>
      <td>NaN</td>
      <td>13-03-2020</td>
      <td>Me: shit buckets, its time to do the weekly s...</td>
      <td>Negative</td>
    </tr>
    <tr>
      <th>803</th>
      <td>804</td>
      <td>45756</td>
      <td>The Outer Limits</td>
      <td>12-03-2020</td>
      <td>@SecPompeo @realDonaldTrump You mean the plan ...</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>2846</th>
      <td>2847</td>
      <td>47799</td>
      <td>Flagstaff, AZ</td>
      <td>15-03-2020</td>
      <td>@lauvagrande People who are sick arent panic ...</td>
      <td>Extremely Negative</td>
    </tr>
    <tr>
      <th>3768</th>
      <td>3769</td>
      <td>48721</td>
      <td>Montreal, Canada</td>
      <td>16-03-2020</td>
      <td>Coronavirus Panic: Toilet Paper Is the People...</td>
      <td>Negative</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Location&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>United States                     63
London, England                   37
Los Angeles, CA                   30
New York, NY                      29
Washington, DC                    29
                                  ..
Suburb of Chicago                  1
philippines                        1
Dont ask for freedom, take it.     1
Windsor Heights, IA                1
St James&#39; Park, Newcastle          1
Name: Location, Length: 1441, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[[</span><span class="s1">&#39;OriginalTweet&#39;</span><span class="p">,</span> <span class="s1">&#39;Location&#39;</span><span class="p">]],</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s1">&#39;OriginalTweet&#39;</span><span class="p">,</span> <span class="s1">&#39;Location&#39;</span><span class="p">]],</span> <span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Negative              852
Positive              743
Neutral               501
Extremely Negative    472
Extremely Positive    470
Name: Sentiment, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scoring_metrics</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="baseline">
<h3>Baseline<a class="headerlink" href="#baseline" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">()</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;dummy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metrics</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>0.001 (+/- 0.000)</td>
      <td>0.000 (+/- 0.000)</td>
      <td>0.280 (+/- 0.001)</td>
      <td>0.280 (+/- 0.000)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="bag-of-words-model">
<h3>Bag-of-words model<a class="headerlink" href="#bag-of-words-model" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">),</span> 
    <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;logistic regression&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;OriginalTweet&#39;</span><span class="p">],</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metrics</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>0.001 (+/- 0.000)</td>
      <td>0.000 (+/- 0.000)</td>
      <td>0.280 (+/- 0.001)</td>
      <td>0.280 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>logistic regression</th>
      <td>0.443 (+/- 0.020)</td>
      <td>0.010 (+/- 0.000)</td>
      <td>0.413 (+/- 0.011)</td>
      <td>0.999 (+/- 0.000)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="is-it-possible-to-further-improve-the-scores">
<h3>Is it possible to further improve the scores?<a class="headerlink" href="#is-it-possible-to-further-improve-the-scores" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>How about adding new features based on our intuitions? Let’s extract our own features that might be useful for this prediction task. In other words, let’s carry out <strong>feature engineering</strong>.</p></li>
<li><p>The code below adds some very basic length-related and sentiment features. We will be using a popular library called <code class="docutils literal notranslate"><span class="pre">nltk</span></code> for this exercise. If you have successfully created the course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment on your machine, you should already have this package in the environment.</p></li>
</ul>
<ul class="simple">
<li><p>How do we extract interesting information from text?</p></li>
<li><p>We use <strong>pre-trained models</strong>!</p></li>
</ul>
<p>A couple of popular libraries which include such pre-trained models.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nltk</span></code></p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">nltk</span> 
</pre></div>
</div>
<ul class="simple">
<li><p>spaCy</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">spacy</span>
</pre></div>
</div>
<p>For emoji support:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacymoji</span>
</pre></div>
</div>
<ul class="simple">
<li><p>You also need to download the language model which contains all the pre-trained models. For that run the following in your course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment or here.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>

<span class="c1"># !python -m spacy download en_core_web_md</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">39</span><span class="p">],</span> <span class="n">line</span> <span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">import</span> <span class="nn">spacy</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># !python -m spacy download en_core_web_md</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;spacy&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;punkt&quot;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;vader_lexicon&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /home/andrew/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package vader_lexicon to
[nltk_data]     /home/andrew/nltk_data...
[nltk_data]   Package vader_lexicon is already up-to-date!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.sentiment.vader</span> <span class="kn">import</span> <span class="n">SentimentIntensityAnalyzer</span>

<span class="n">sid</span> <span class="o">=</span> <span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;CPSC 330 students are smart, sweet, and funny.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;neg&#39;: 0.0, &#39;neu&#39;: 0.368, &#39;pos&#39;: 0.632, &#39;compound&#39;: 0.8225}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s</span> <span class="o">=</span> <span class="s2">&quot;CPSC 330 students are tired because of all the hard work they have been doing.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;neg&#39;: 0.249, &#39;neu&#39;: 0.751, &#39;pos&#39;: 0.0, &#39;compound&#39;: -0.5106}
</pre></div>
</div>
</div>
</div>
</section>
<section id="spacy">
<h3><a class="reference external" href="https://spacy.io/">spaCy</a><a class="headerlink" href="#spacy" title="Permalink to this heading">#</a></h3>
<p>A useful package for text processing and feature extraction</p>
<ul class="simple">
<li><p>Active development: https://github.com/explosion/spaCy</p></li>
<li><p>Interactive lessons by Ines Montani: https://course.spacy.io/en/</p></li>
<li><p>Good documentation, easy to use, and customizable.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">en_core_web_md</span>  <span class="c1"># pre-trained model</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">en_core_web_md</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Dolly Parton is a gift to us all. </span>
<span class="s2">From writing all-time great songs like “Jolene” and “I Will Always Love You”, </span>
<span class="s2">to great performances in films like 9 to 5, to helping fund a COVID-19 vaccine, </span>
<span class="s2">she’s given us so much. Now, Netflix bring us Dolly Parton’s Christmas on the Square, </span>
<span class="s2">an original musical that stars Christine Baranski as a Scrooge-like landowner </span>
<span class="s2">who threatens to evict an entire town on Christmas Eve to make room for a new mall. </span>
<span class="s2">Directed and choreographed by the legendary Debbie Allen and counting Jennifer Lewis </span>
<span class="s2">and Parton herself amongst its cast, Christmas on the Square seems like the perfect movie</span>
<span class="s2">to save Christmas 2020. 😻 👍🏿&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://thepopbreak.com/2020/11/22/dolly-partons-christmas-on-the-square-review-not-quite-a-christmas-miracle/">Adapted from here.</a></p>
<p>Spacy extracts all interesting information from text with this call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at part-of-speech tags.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">([(</span><span class="n">token</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">][:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(Dolly, &#39;PROPN&#39;), (Parton, &#39;PROPN&#39;), (is, &#39;AUX&#39;), (a, &#39;DET&#39;), (gift, &#39;NOUN&#39;), (to, &#39;ADP&#39;), (us, &#39;PRON&#39;), (all, &#39;PRON&#39;), (., &#39;PUNCT&#39;), (
, &#39;SPACE&#39;), (From, &#39;ADP&#39;), (writing, &#39;VERB&#39;), (all, &#39;DET&#39;), (-, &#39;PUNCT&#39;), (time, &#39;NOUN&#39;), (great, &#39;ADJ&#39;), (songs, &#39;NOUN&#39;), (like, &#39;ADP&#39;), (“, &#39;PUNCT&#39;), (Jolene, &#39;PROPN&#39;)]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Often we want to know who did what to whom.</p></li>
<li><p><strong>Named entities</strong> give you this information.</p></li>
<li><p>What are named entities in the text?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Named entities:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">ORG means: &quot;</span><span class="p">,</span> <span class="n">spacy</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="s2">&quot;ORG&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">PERSON means: &quot;</span><span class="p">,</span> <span class="n">spacy</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="s2">&quot;PERSON&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">DATE means: &quot;</span><span class="p">,</span> <span class="n">spacy</span><span class="o">.</span><span class="n">explain</span><span class="p">(</span><span class="s2">&quot;DATE&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Named entities:
 [(&#39;Dolly Parton&#39;, &#39;PERSON&#39;), (&#39;Jolene&#39;, &#39;PERSON&#39;), (&#39;9 to 5&#39;, &#39;DATE&#39;), (&#39;Netflix&#39;, &#39;ORG&#39;), (&#39;Dolly Parton&#39;, &#39;PERSON&#39;), (&#39;Christmas&#39;, &#39;DATE&#39;), (&#39;Square&#39;, &#39;FAC&#39;), (&#39;Christine Baranski&#39;, &#39;PERSON&#39;), (&#39;Christmas Eve&#39;, &#39;DATE&#39;), (&#39;Debbie Allen&#39;, &#39;PERSON&#39;), (&#39;Jennifer Lewis&#39;, &#39;PERSON&#39;), (&#39;Parton&#39;, &#39;PERSON&#39;), (&#39;Christmas&#39;, &#39;DATE&#39;), (&#39;Square&#39;, &#39;FAC&#39;), (&#39;Christmas 2020&#39;, &#39;DATE&#39;)]

ORG means:  Companies, agencies, institutions, etc.

PERSON means:  People, including fictional

DATE means:  Absolute or relative dates or periods
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">spacy</span> <span class="kn">import</span> <span class="n">displacy</span>

<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;ent&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><div class="entities" style="line-height: 2.5; direction: ltr">
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Dolly Parton
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 is a gift to us all. <br>From writing all-time great songs like “
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Jolene
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
” and “I Will Always Love You”, <br>to great performances in films like 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    9 to 5
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
, to helping fund a COVID-19 vaccine, <br>she’s given us so much. Now, 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Netflix
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 bring us 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Dolly Parton
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
’s 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 on the 
<mark class="entity" style="background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Square
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">FAC</span>
</mark>
, <br>an original musical that stars 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christine Baranski
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 as a Scrooge-like landowner <br>who threatens to evict an entire town on 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas Eve
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 to make room for a new mall. <br>Directed and choreographed by the legendary 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Debbie Allen
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 and counting 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Jennifer Lewis
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 <br>and 
<mark class="entity" style="background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Parton
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PERSON</span>
</mark>
 herself amongst its cast, 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
 on the 
<mark class="entity" style="background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Square
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">FAC</span>
</mark>
 seems like the perfect movie<br>to save 
<mark class="entity" style="background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Christmas 2020
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">DATE</span>
</mark>
. 😻 👍🏿</div></span></div></div>
</div>
</section>
<section id="an-example-from-a-project">
<h3>An example from a project<a class="headerlink" href="#an-example-from-a-project" title="Permalink to this heading">#</a></h3>
<p>Goal: Extract and visualize inter-corporate relationships from disclosed annual 10-K reports of public companies.</p>
<p><a class="reference external" href="https://www.bbc.com/news/business-39875417">Source for the text below.</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Heavy hitters, including Microsoft and Google, &quot;</span>
    <span class="s2">&quot;are competing for customers in cloud services with the likes of IBM and Salesforce.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;ent&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Named entities:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">[(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><div class="entities" style="line-height: 2.5; direction: ltr">Heavy hitters, including 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Microsoft
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 and 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Google
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
, are competing for customers in cloud services with the likes of 
<mark class="entity" style="background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    IBM
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">ORG</span>
</mark>
 and 
<mark class="entity" style="background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    Salesforce
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem">PRODUCT</span>
</mark>
.</div></span></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Named entities:
 [(&#39;Microsoft&#39;, &#39;ORG&#39;), (&#39;Google&#39;, &#39;ORG&#39;), (&#39;IBM&#39;, &#39;ORG&#39;), (&#39;Salesforce&#39;, &#39;PRODUCT&#39;)]
</pre></div>
</div>
</div>
</div>
<p>If you want emoji identification support install <a class="reference external" href="https://pypi.org/project/spacymoji/"><code class="docutils literal notranslate"><span class="pre">spacymoji</span></code></a> in the course environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacymoji</span>
</pre></div>
</div>
<p>After installing <code class="docutils literal notranslate"><span class="pre">spacymoji</span></code>, if it’s still complaining about module not found, my guess is that you do not have <code class="docutils literal notranslate"><span class="pre">pip</span></code> installed in your <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment. Go to your course <code class="docutils literal notranslate"><span class="pre">conda</span></code> environment install <code class="docutils literal notranslate"><span class="pre">pip</span></code> and install the <code class="docutils literal notranslate"><span class="pre">spacymoji</span></code> package in the environment using the <code class="docutils literal notranslate"><span class="pre">pip</span></code> you just installed in the current environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="n">pip</span>
<span class="n">YOUR_MINICONDA_PATH</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">cpsc330</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">pip</span> <span class="n">install</span> <span class="n">spacymoji</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">spacymoji</span> <span class="kn">import</span> <span class="n">Emoji</span>

<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;emoji&quot;</span><span class="p">,</span> <span class="n">first</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Does the text have any emojis? If yes, extract the description.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>
<span class="n">doc</span><span class="o">.</span><span class="n">_</span><span class="o">.</span><span class="n">emoji</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;😻&#39;, 138, &#39;smiling cat with heart-eyes&#39;),
 (&#39;👍🏿&#39;, 139, &#39;thumbs up dark skin tone&#39;)]
</pre></div>
</div>
</div>
</div>
<section id="simple-feature-engineering-for-our-problem">
<h4>Simple feature engineering for our problem.<a class="headerlink" href="#simple-feature-engineering-for-our-problem" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">en_core_web_md</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">en_core_web_md</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
<span class="kn">from</span> <span class="nn">spacymoji</span> <span class="kn">import</span> <span class="n">Emoji</span>

<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;emoji&quot;</span><span class="p">,</span> <span class="n">first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_relative_length</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">TWITTER_ALLOWED_CHARS</span><span class="o">=</span><span class="mf">280.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the relative length of text.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ------</span>
<span class="sd">    text: (str)</span>
<span class="sd">    the input text</span>

<span class="sd">    Keyword arguments:</span>
<span class="sd">    ------</span>
<span class="sd">    TWITTER_ALLOWED_CHARS: (float)</span>
<span class="sd">    the denominator for finding relative length</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    relative length of text: (float)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">/</span> <span class="n">TWITTER_ALLOWED_CHARS</span>


<span class="k">def</span> <span class="nf">get_length_in_words</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the length of the text in words.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ------</span>
<span class="sd">    text: (str)</span>
<span class="sd">    the input text</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    length of tokenized text: (int)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_sentiment</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the compound score representing the sentiment: -1 (most extreme negative) and +1 (most extreme positive)</span>
<span class="sd">    The compound score is a normalized score calculated by summing the valence scores of each word in the lexicon.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ------</span>
<span class="sd">    text: (str)</span>
<span class="sd">    the input text</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    sentiment of the text: (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">sid</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">[</span><span class="s2">&quot;compound&quot;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">get_avg_word_length</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the average word length of the given text.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    text -- (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">has_emoji</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the average word length of the given text.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    text -- (str)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">doc</span><span class="o">.</span><span class="n">_</span><span class="o">.</span><span class="n">has_emoji</span> <span class="k">else</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">n_words</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_length_in_words</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">vader_sentiment</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_sentiment</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">rel_char_len</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_relative_length</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">average_word_length</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_avg_word_length</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">all_caps</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">has_emoji</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_emoji</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">n_words</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_length_in_words</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">vader_sentiment</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_sentiment</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">rel_char_len</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_relative_length</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">average_word_length</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">get_avg_word_length</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">all_caps</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span>
    <span class="n">has_emoji</span><span class="o">=</span><span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;OriginalTweet&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">has_emoji</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserName</th>
      <th>ScreenName</th>
      <th>Location</th>
      <th>TweetAt</th>
      <th>OriginalTweet</th>
      <th>Sentiment</th>
      <th>n_words</th>
      <th>vader_sentiment</th>
      <th>rel_char_len</th>
      <th>average_word_length</th>
      <th>all_caps</th>
      <th>has_emoji</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1927</th>
      <td>1928</td>
      <td>46880</td>
      <td>Seattle, WA</td>
      <td>13-03-2020</td>
      <td>While I don't like all of Amazon's choices, to...</td>
      <td>Positive</td>
      <td>31</td>
      <td>-0.1053</td>
      <td>0.589286</td>
      <td>5.640000</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1068</th>
      <td>1069</td>
      <td>46021</td>
      <td>NaN</td>
      <td>13-03-2020</td>
      <td>Me: shit buckets, its time to do the weekly s...</td>
      <td>Negative</td>
      <td>52</td>
      <td>-0.2500</td>
      <td>0.932143</td>
      <td>4.636364</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3038, 12)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;all_caps&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Sentiment&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;vader_sentiment&#39;</span><span class="p">,</span> <span class="s1">&#39;rel_char_len&#39;</span><span class="p">,</span> <span class="s1">&#39;average_word_length&#39;</span>
<span class="p">]</span>
<span class="n">passthrough_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;all_caps&#39;</span><span class="p">,</span> <span class="s1">&#39;has_emoji&#39;</span><span class="p">]</span> 
<span class="n">text_feature</span> <span class="o">=</span> <span class="s1">&#39;OriginalTweet&#39;</span>
<span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;UserName&#39;</span><span class="p">,</span> <span class="s1">&#39;ScreenName&#39;</span><span class="p">,</span> <span class="s1">&#39;Location&#39;</span><span class="p">,</span> <span class="s1">&#39;TweetAt&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">numeric_features</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;passthrough&quot;</span><span class="p">,</span> <span class="n">passthrough_features</span><span class="p">),</span> 
    <span class="p">(</span><span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">),</span> <span class="n">text_feature</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;drop&quot;</span><span class="p">,</span> <span class="n">drop_features</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;LR (more feats)&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metrics</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fit_time</th>
      <th>score_time</th>
      <th>test_score</th>
      <th>train_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>dummy</th>
      <td>0.002 (+/- 0.000)</td>
      <td>0.001 (+/- 0.000)</td>
      <td>0.280 (+/- 0.001)</td>
      <td>0.280 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>logistic regression</th>
      <td>1.914 (+/- 0.119)</td>
      <td>0.074 (+/- 0.004)</td>
      <td>0.413 (+/- 0.011)</td>
      <td>0.999 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>LR (more feats)</th>
      <td>2.081 (+/- 0.077)</td>
      <td>0.090 (+/- 0.001)</td>
      <td>0.689 (+/- 0.007)</td>
      <td>0.998 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We get some improvements with our engineered features!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv_feats</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;columntransformer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s1">&#39;countvectorizer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feat_names</span> <span class="o">=</span> <span class="n">numeric_features</span> <span class="o">+</span> <span class="n">passthrough_features</span> <span class="o">+</span> <span class="n">cv_feats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;logisticregression&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;features&quot;</span><span class="p">:</span> <span class="n">feat_names</span><span class="p">,</span>
        <span class="s2">&quot;coefficients&quot;</span><span class="p">:</span> <span class="n">coefs</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;coefficients&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>features</th>
      <th>coefficients</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>vader_sentiment</td>
      <td>-6.141919</td>
    </tr>
    <tr>
      <th>11331</th>
      <td>won</td>
      <td>-1.369740</td>
    </tr>
    <tr>
      <th>2551</th>
      <td>coronapocalypse</td>
      <td>-0.809931</td>
    </tr>
    <tr>
      <th>2214</th>
      <td>closed</td>
      <td>-0.744717</td>
    </tr>
    <tr>
      <th>8661</th>
      <td>retail</td>
      <td>-0.723808</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9862</th>
      <td>stupid</td>
      <td>1.157669</td>
    </tr>
    <tr>
      <th>3299</th>
      <td>don</td>
      <td>1.159067</td>
    </tr>
    <tr>
      <th>4879</th>
      <td>hell</td>
      <td>1.311957</td>
    </tr>
    <tr>
      <th>3129</th>
      <td>die</td>
      <td>1.366538</td>
    </tr>
    <tr>
      <th>7504</th>
      <td>panic</td>
      <td>1.527156</td>
    </tr>
  </tbody>
</table>
<p>11664 rows × 2 columns</p>
</div></div></div>
</div>
<p>Check <span class="xref myst">Appendix-A</span> for commonly used features in text classification.</p>
</section>
</section>
<section id="interim-summary">
<h3>Interim summary<a class="headerlink" href="#interim-summary" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Feature engineering is finding the useful representation of the data that can help us effectively solve our problem.</p></li>
<li><p>In the context of text data, if we want to go beyond bag-of-words and incorporate human knowledge in models, we carry out feature engineering.</p></li>
<li><p>Some common features include:</p>
<ul>
<li><p>ngram features</p></li>
<li><p>part-of-speech features</p></li>
<li><p>named entity features</p></li>
<li><p>emoticons in text</p></li>
</ul>
</li>
<li><p>These are usually extracted from pre-trained models using libraries such as <code class="docutils literal notranslate"><span class="pre">spaCy</span></code>.</p></li>
<li><p>Now a lot of this has moved to deep learning.</p></li>
<li><p>But many industries still rely on manual feature engineering.</p></li>
</ul>
</section>
<section id="feature-engineering">
<h3>Feature engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The best features are application-dependent.</p></li>
<li><p>It’s hard to give general advice. But here are some guidelines.</p>
<ul>
<li><p>Ask the domain experts.</p></li>
<li><p>Go through academic papers in the discipline.</p></li>
<li><p>Often have idea of right discretization/standardization/transformation.</p></li>
<li><p>If no domain expert, cross-validation will help.</p></li>
</ul>
</li>
<li><p>If you have lots of data, use deep learning methods.</p></li>
</ul>
<blockquote>
    The algorithms we used are very standard for Kagglers ... We spent most of our efforts in feature engineering... <br>
- Xavier Conort, on winning the Flight Quest challenge on Kaggle    
</blockquote>    </section>
</section>
<section id="feature-selection-introduction-and-motivation">
<h2>Feature selection: Introduction and motivation<a class="headerlink" href="#feature-selection-introduction-and-motivation" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>With so many ways to add new features, we can increase dimensionality of the data.</p></li>
<li><p>More features means more complex models, which means increasing the chance of overfitting.</p></li>
</ul>
<section id="what-is-feature-selection">
<h3>What is feature selection?<a class="headerlink" href="#what-is-feature-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Find the features	(columns) <span class="math notranslate nohighlight">\(X\)</span> that are important for predicting	<span class="math notranslate nohighlight">\(y\)</span>, and remove the features that aren’t.</p></li>
<li><p>Given <span class="math notranslate nohighlight">\(X = \begin{bmatrix}x_1 &amp; x_2 &amp; \dots &amp; x_n\\  \\  \\  \end{bmatrix}\)</span> and <span class="math notranslate nohighlight">\(y = \begin{bmatrix}\\  \\  \\  \end{bmatrix}\)</span>, find the columns <span class="math notranslate nohighlight">\(1 \leq j \leq n\)</span> in <span class="math notranslate nohighlight">\(X\)</span> that are important for predicting <span class="math notranslate nohighlight">\(y\)</span>.</p></li>
</ul>
</section>
<section id="why-feature-selection">
<h3>Why feature selection?<a class="headerlink" href="#why-feature-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Interpretability: Models are more interpretable with fewer features. If you get the same performance with 10 features instead of 500 features, why not use the model with smaller number of features?</p></li>
<li><p>Computation: Models fit/predict faster with fewer columns.</p></li>
<li><p>Data collection: What type of new data should I collect? It may be cheaper to collect fewer columns.</p></li>
<li><p>Fundamental tradeoff: Can I reduce overfitting by removing useless features?</p></li>
</ul>
<p>Feature selection can often result in better performing (less overfit), easier to understand, and faster model.</p>
</section>
<section id="how-do-we-carry-out-feature-selection">
<h3>How do we carry out feature selection?<a class="headerlink" href="#how-do-we-carry-out-feature-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>There are a number of ways.</p></li>
<li><p>You could use domain knowledge to discard features.</p></li>
<li><p>We are briefly going to look at some automatic feature selection methods from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>:</p>
<ul>
<li><p>Model-based selection</p></li>
<li><p>Recursive feature elimination</p></li>
<li><p>Forward/backward selection</p></li>
</ul>
</li>
<li><p>Very related to looking at feature importances.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s2">&quot;frame&quot;</span><span class="p">]</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span>
<span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>mean smoothness</th>
      <th>mean compactness</th>
      <th>mean concavity</th>
      <th>mean concave points</th>
      <th>mean symmetry</th>
      <th>mean fractal dimension</th>
      <th>...</th>
      <th>worst texture</th>
      <th>worst perimeter</th>
      <th>worst area</th>
      <th>worst smoothness</th>
      <th>worst compactness</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>395</th>
      <td>14.06</td>
      <td>17.18</td>
      <td>89.75</td>
      <td>609.1</td>
      <td>0.08045</td>
      <td>0.05361</td>
      <td>0.02681</td>
      <td>0.03251</td>
      <td>0.1641</td>
      <td>0.05764</td>
      <td>...</td>
      <td>25.34</td>
      <td>96.42</td>
      <td>684.5</td>
      <td>0.1066</td>
      <td>0.1231</td>
      <td>0.0846</td>
      <td>0.07911</td>
      <td>0.2523</td>
      <td>0.06609</td>
      <td>1</td>
    </tr>
    <tr>
      <th>393</th>
      <td>21.61</td>
      <td>22.28</td>
      <td>144.40</td>
      <td>1407.0</td>
      <td>0.11670</td>
      <td>0.20870</td>
      <td>0.28100</td>
      <td>0.15620</td>
      <td>0.2162</td>
      <td>0.06606</td>
      <td>...</td>
      <td>28.74</td>
      <td>172.00</td>
      <td>2081.0</td>
      <td>0.1502</td>
      <td>0.5717</td>
      <td>0.7053</td>
      <td>0.24220</td>
      <td>0.3828</td>
      <td>0.10070</td>
      <td>0</td>
    </tr>
    <tr>
      <th>381</th>
      <td>11.04</td>
      <td>14.93</td>
      <td>70.67</td>
      <td>372.7</td>
      <td>0.07987</td>
      <td>0.07079</td>
      <td>0.03546</td>
      <td>0.02074</td>
      <td>0.2003</td>
      <td>0.06246</td>
      <td>...</td>
      <td>20.83</td>
      <td>79.73</td>
      <td>447.1</td>
      <td>0.1095</td>
      <td>0.1982</td>
      <td>0.1553</td>
      <td>0.06754</td>
      <td>0.3202</td>
      <td>0.07287</td>
      <td>1</td>
    </tr>
    <tr>
      <th>198</th>
      <td>19.18</td>
      <td>22.49</td>
      <td>127.50</td>
      <td>1148.0</td>
      <td>0.08523</td>
      <td>0.14280</td>
      <td>0.11140</td>
      <td>0.06772</td>
      <td>0.1767</td>
      <td>0.05529</td>
      <td>...</td>
      <td>32.06</td>
      <td>166.40</td>
      <td>1688.0</td>
      <td>0.1322</td>
      <td>0.5601</td>
      <td>0.3865</td>
      <td>0.17080</td>
      <td>0.3193</td>
      <td>0.09221</td>
      <td>0</td>
    </tr>
    <tr>
      <th>145</th>
      <td>11.90</td>
      <td>14.65</td>
      <td>78.11</td>
      <td>432.8</td>
      <td>0.11520</td>
      <td>0.12960</td>
      <td>0.03710</td>
      <td>0.03003</td>
      <td>0.1995</td>
      <td>0.07839</td>
      <td>...</td>
      <td>16.51</td>
      <td>86.26</td>
      <td>509.6</td>
      <td>0.1424</td>
      <td>0.2517</td>
      <td>0.0942</td>
      <td>0.06042</td>
      <td>0.2727</td>
      <td>0.10360</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(284, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_l2_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">lr_l2_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.007631
score_time     0.001830
test_score     0.968233
train_score    0.987681
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_l2_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">lr_l2_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logisticregression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mean radius               -0.219333
mean texture              -0.543376
mean perimeter            -0.215956
mean area                 -0.293937
mean smoothness           -0.065450
mean compactness           0.192030
mean concavity            -0.655450
mean concave points       -0.850999
mean symmetry             -0.446818
mean fractal dimension     0.095681
radius error              -1.314711
texture error             -0.027409
perimeter error           -0.857302
area error                -0.756209
smoothness error           0.329308
compactness error          0.836200
concavity error            0.020990
concave points error      -0.306175
symmetry error             0.135889
fractal dimension error    0.875058
worst radius              -0.799151
worst texture             -0.688446
worst perimeter           -0.626146
worst area                -0.689233
worst smoothness          -0.384255
worst compactness         -0.047503
worst concavity           -0.860896
worst concave points      -1.091686
worst symmetry            -0.357159
worst fractal dimension   -0.436556
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="linear-models-recap">
<h3>Linear models recap<a class="headerlink" href="#linear-models-recap" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Recall that in linear regression our predictons are given by
$<span class="math notranslate nohighlight">\(\hat{y_i} = \sum_j w_j x_{i j} + b\)</span>$</p></li>
<li><p>To estimate the coefficients <span class="math notranslate nohighlight">\(w_j\)</span>, linear regression tries to minimize the following equation
$<span class="math notranslate nohighlight">\( \sum_i |\hat{y_i} - y_i|^2\)</span>$
that is the squared error between predicted and observed values.</p></li>
</ul>
<section id="ridge-regression-l2-penalty">
<h4>Ridge regression (L2 penalty)<a class="headerlink" href="#ridge-regression-l2-penalty" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>In this course we have said to use Ridge instead of LinearRegression to avoid overfitting the coefficients</p></li>
<li><p>In Ridge regression we still predict values using <span class="math notranslate nohighlight">\(\hat{y_i} = \sum_j w_j x_{i j} + b\)</span></p></li>
<li><p>But to estimate the coefficients we <strong>minimize</strong> a different equation
<br>
$<span class="math notranslate nohighlight">\( \sum_i |\hat{y_i} - y_i|^2 + \alpha \sum_j |w_j|^2 \)</span>$</p></li>
<li><p>The term <span class="math notranslate nohighlight">\(\sum_j |w_j|^2\)</span> is a penalty which discourages large coefficients.</p></li>
<li><p>The strength of the penalty is controlled by <span class="math notranslate nohighlight">\(\alpha\)</span> which we have seen can be tuned using cross-validation.</p></li>
</ul>
</section>
<section id="lasso-regression-l1-penalty">
<h4>Lasso regression (L1 penalty)<a class="headerlink" href="#lasso-regression-l1-penalty" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>We can consider other penalties instead of <span class="math notranslate nohighlight">\(\sum_j |w_j|^2\)</span>.</p>
<ul>
<li><p>But we still predict values using <span class="math notranslate nohighlight">\(\hat{y_i} = \sum_j w_j x_{i j} + b\)</span></p></li>
</ul>
</li>
<li><p>A very common choice of penalty to use the absolute value <span class="math notranslate nohighlight">\(\sum_j |w_j|\)</span></p>
<ul>
<li><p>This called the L1 norm because the absolute value is to the power 1</p></li>
</ul>
</li>
<li><p>To estimate the coefficients we <strong>minimize</strong>
<br>
$<span class="math notranslate nohighlight">\( \sum_i |\hat{y_i} - y_i|^2 + \alpha \sum_j |w_j| \)</span>$</p></li>
<li><p>This is callled Lasso regression and is implemented in the <code class="docutils literal notranslate"><span class="pre">sklearn.linear_model.Lasso</span></code> class</p></li>
<li><p>An interesting feature of using the L1 penalty is that it will often set coefficients to zero!</p>
<ul>
<li><p>This can be considered a form of feature selection.</p></li>
</ul>
</li>
</ul>
</section>
<section id="logistic-regression-l1-and-l2">
<h4>Logistic regression (L1 and L2)<a class="headerlink" href="#logistic-regression-l1-and-l2" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>We have focused on linear regression so far, but the same ideas apply to LogisticRegression.</p></li>
<li><p>The two main differences:</p>
<ol class="arabic simple">
<li><p>We use a sigmoid for predicting i.e. <span class="math notranslate nohighlight">\(\hat{y_i} = \sigma(\sum_j w_j x_{i j} + b)\)</span>
<br></p></li>
<li><p>We replace <span class="math notranslate nohighlight">\(|\hat{y_i} - y_i|^2\)</span> with a different equation appropriate for classification.</p></li>
</ol>
</li>
<li><p>By default scikit-learn uses an L2 penalty for LogisticRegression.</p>
<ul>
<li><p>You can change this using the <code class="docutils literal notranslate"><span class="pre">penalty</span></code> argument.</p></li>
<li><p>You may have to also change the <code class="docutils literal notranslate"><span class="pre">solver</span></code> argument.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_l1_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">lr_l1_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.004590
score_time     0.001571
test_score     0.968296
train_score    0.986803
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lr_l1_pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">lr_l1_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logisticregression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mean radius                0.000000
mean texture              -0.171052
mean perimeter             0.000000
mean area                  0.000000
mean smoothness            0.000000
mean compactness           0.000000
mean concavity             0.000000
mean concave points       -0.437340
mean symmetry             -0.366957
mean fractal dimension     0.000000
radius error              -2.899951
texture error              0.000000
perimeter error            0.000000
area error                 0.000000
smoothness error           0.000000
compactness error          0.605914
concavity error            0.000000
concave points error       0.000000
symmetry error             0.000000
fractal dimension error    0.765894
worst radius              -2.237705
worst texture             -1.020974
worst perimeter            0.000000
worst area                 0.000000
worst smoothness           0.000000
worst compactness          0.000000
worst concavity           -1.256502
worst concave points      -2.353609
worst symmetry            -0.065019
worst fractal dimension    0.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L1 logistic regression uses </span><span class="si">{}</span><span class="s2"> features&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lr_l1_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logisticregression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;L2 logistic regression uses </span><span class="si">{}</span><span class="s2"> features&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lr_l2_pipe</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logisticregression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>L1 logistic regression uses 11 features
L2 logistic regression uses 30 features
</pre></div>
</div>
</div>
</div>
</section>
<section id="l1-vs-l2-penalty-summary">
<h4>L1 vs L2 penalty summary<a class="headerlink" href="#l1-vs-l2-penalty-summary" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>The L1 penalty will usually set some coefficients to zero</p></li>
<li><p>The L2 penalty will make coefficients smaller but rarely set them to zero</p></li>
<li><p>When correlated variables are present:</p>
<ul>
<li><p>L1 will usually keep one and set the other coefficients to zero</p></li>
<li><p>L2 will usually shrink the coefficient of all of them</p></li>
</ul>
</li>
<li><p>L1 and L2 penalties can be combined!</p>
<ul>
<li><p>This is called the <strong>elastic net</strong> penalty and is available in sklearn.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="model-based-selection">
<h3>Model-based selection<a class="headerlink" href="#model-based-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Use a supervised machine learning model to judge the importance of each feature.</p></li>
<li><p>Keep only the most important once.</p></li>
<li><p>Supervised machine learning model used for feature selection can be different that the one used as the final estimator.</p></li>
<li><p>Use a model which has some way to calculate feature importances.</p></li>
</ul>
<ul class="simple">
<li><p>To use model-based selection, we use <code class="docutils literal notranslate"><span class="pre">SelectFromModel</span></code> transformer.</p></li>
<li><p>It selects features which have the feature importances greater than the provided threshold.</p></li>
<li><p>Below I’m using <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> for feature selection with threahold “median” of feature importances.</p></li>
<li><p>Approximately how many features will be selected?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>

<span class="n">select_rf</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> 
    <span class="n">threshold</span><span class="o">=</span><span class="s2">&quot;median&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can put the feature selection transformer in a pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_model_based</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">select_rf</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_lr_model_based</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       0.187817
score_time     0.011451
test_score     0.950564
train_score    0.974480
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Note that RandomForest is doing the feature selction and LogisticRegression is doing the classification with the reduced set of features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_model_based</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pipe_lr_model_based</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;selectfrommodel&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/andrew/.install/opt/mamba/envs/cpsc330/lib/python3.10/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but SelectFromModel was fitted without feature names
  warnings.warn(
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(284, 15)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Similar results with only 15 features instead of 30 features.</p></li>
<li><p>Interestingly L1 regularization does better with fewer features here but that will vary on other data.</p></li>
</ul>
<p>Can we use KNN to select features?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">select_knn</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span>
    <span class="n">KNeighborsClassifier</span><span class="p">(),</span> 
    <span class="n">threshold</span><span class="o">=</span><span class="s2">&quot;median&quot;</span>
<span class="p">)</span>

<span class="n">pipe_lr_model_based</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">select_knn</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1">#pd.DataFrame(</span>
<span class="c1">#    cross_validate(pipe_lr_model_based, X_train, y_train, return_train_score=True)#</span>
<span class="c1">#).mean()</span>
</pre></div>
</div>
</div>
</div>
<p><strong>No</strong> KNN won’t work since it does not report feature importances.</p>
<p>What about SVC?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">select_svc</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span>
    <span class="n">SVC</span><span class="p">(),</span> <span class="n">threshold</span><span class="o">=</span><span class="s2">&quot;median&quot;</span>
<span class="p">)</span>

<span class="c1"># pipe_lr_model_based = make_pipeline(</span>
<span class="c1">#     StandardScaler(), select_svc, LogisticRegression(max_iter=1000)</span>
<span class="c1"># )</span>

<span class="c1"># pd.DataFrame(</span>
<span class="c1">#    cross_validate(pipe_lr_model_based, X_train, y_train, return_train_score=True)</span>
<span class="c1"># ).mean()</span>
</pre></div>
</div>
</div>
</div>
<p>Only with a linear kernel but not with RBF kernel</p>
</section>
<section id="iclicker-exercise-13-2">
<h3>(iClicker) Exercise 13.2<a class="headerlink" href="#iclicker-exercise-13-2" title="Permalink to this heading">#</a></h3>
<p><strong>iClicker cloud join link: https://join.iclicker.com/SNBF</strong></p>
<p><strong>Select all of the following statements which are TRUE.</strong></p>
<ul class="simple">
<li><p>(A) L2 regularized logistic regression sets correlated coefficients to zero</p></li>
<li><p>(B) Lasso regression predicts values using <span class="math notranslate nohighlight">\(\hat{y_i} = \sum_j w_j x_{i j} + b\)</span></p></li>
<li><p>(C) Lasso and Ridge regression optimize different measures of difference between predicted and observe target values</p></li>
<li><p>(D) KNN and SVM RBF can be used with SelectFromModel</p></li>
<li><p>(E) I saw way to much math today!</p></li>
</ul>
</section>
<section id="recursive-feature-elimination-rfe">
<h3>Recursive feature elimination (RFE)<a class="headerlink" href="#recursive-feature-elimination-rfe" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Build a series of models</p></li>
<li><p>At each iteration, discard the least important feature according to the model.</p></li>
<li><p>Computationally expensive</p></li>
<li><p>Basic idea</p>
<ul>
<li><p>fit model</p></li>
<li><p>find least important feature</p></li>
<li><p>remove</p></li>
<li><p>iterate.</p></li>
</ul>
</li>
</ul>
</section>
<section id="rfe-algorithm">
<h3>RFE algorithm<a class="headerlink" href="#rfe-algorithm" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Decide <span class="math notranslate nohighlight">\(k\)</span>, the number of features to select.</p></li>
<li><p>Assign importances to features, e.g. by fitting a model and looking at <code class="docutils literal notranslate"><span class="pre">coef_</span></code> or <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code>.</p></li>
<li><p>Remove the least important feature.</p></li>
<li><p>Repeat steps 2-3 until only <span class="math notranslate nohighlight">\(k\)</span> features are remaining.</p></li>
</ol>
<p>Note that this is <strong>not</strong> the same as just removing all the less important features in one shot!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># create ranking of features</span>
<span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">n_features_to_select</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">rfe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rfe</span><span class="o">.</span><span class="n">ranking_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([16, 12, 19, 13, 23, 20, 10,  1,  9, 22,  2, 25,  5,  7, 15,  4, 26,
       18, 21,  8,  1,  1,  1,  6, 14, 24,  3,  1, 17, 11])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[False False False False False False False  True False False False False
 False False False False False False False False  True  True  True False
 False False False  True False False]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;selected features: &quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">rfe</span><span class="o">.</span><span class="n">support_</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>selected features:  Index([&#39;mean concave points&#39;, &#39;worst radius&#39;, &#39;worst texture&#39;,
       &#39;worst perimeter&#39;, &#39;worst concave points&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>How do we know what value to pass to <code class="docutils literal notranslate"><span class="pre">n_features_to_select</span></code>?</p></li>
</ul>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">RFECV</span></code> which uses cross-validation to select number of features.</p></li>
</ul>
<p>For illustration purposes</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFECV</span>

<span class="n">rfe_cv</span> <span class="o">=</span> <span class="n">RFECV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">rfe_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rfe_cv</span><span class="o">.</span><span class="n">support_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">rfe_cv</span><span class="o">.</span><span class="n">support_</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[False  True False  True False False  True  True  True False  True False
  True  True False  True False False False  True  True  True  True  True
 False False  True  True False  True]
Index([&#39;mean texture&#39;, &#39;mean area&#39;, &#39;mean concavity&#39;, &#39;mean concave points&#39;,
       &#39;mean symmetry&#39;, &#39;radius error&#39;, &#39;perimeter error&#39;, &#39;area error&#39;,
       &#39;compactness error&#39;, &#39;fractal dimension error&#39;, &#39;worst radius&#39;,
       &#39;worst texture&#39;, &#39;worst perimeter&#39;, &#39;worst area&#39;, &#39;worst concavity&#39;,
       &#39;worst concave points&#39;, &#39;worst fractal dimension&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>But we should really use pipelines</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rfe_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">RFECV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">),</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">rfe_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       1.430083
score_time     0.008701
test_score     0.943609
train_score    1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Slow because there is cross validation within cross validation</p></li>
<li><p>Not a big improvement in scores compared to all features on this toy case</p></li>
</ul>
</section>
<section id="optional-search-and-score">
<h3>(Optional) Search and score<a class="headerlink" href="#optional-search-and-score" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Define a <strong>scoring function</strong> <span class="math notranslate nohighlight">\(f(S)\)</span> that measures the quality of the set of features <span class="math notranslate nohighlight">\(S\)</span>.</p></li>
<li><p>Now <strong>search</strong> for the set of features <span class="math notranslate nohighlight">\(S\)</span> with the best score.</p></li>
</ul>
</section>
<section id="general-idea-of-search-and-score-methods">
<h3>General idea of search and score methods<a class="headerlink" href="#general-idea-of-search-and-score-methods" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Example: Suppose you have three features: <span class="math notranslate nohighlight">\(A, B, C\)</span></p>
<ul>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S= \{B\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{C\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A,B\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A,C\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{B,C\}\)</span></p></li>
<li><p>Compute <strong>score</strong> for <span class="math notranslate nohighlight">\(S = \{A,B,C\}\)</span></p></li>
</ul>
</li>
<li><p>Return <span class="math notranslate nohighlight">\(S\)</span> with the best score.</p></li>
<li><p>How many distinct combinations do we have to try out?</p></li>
</ul>
</section>
<section id="optional-forward-or-backward-selection">
<h3>(Optional) Forward or backward selection<a class="headerlink" href="#optional-forward-or-backward-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Also called wrapper methods</p></li>
<li><p>Shrink or grow feature set by removing or adding one feature at a time</p></li>
<li><p>Makes the decision based on whether adding/removing the feature improves the CV score or not</p></li>
</ul>
<p><img alt="" src="../../_images/forward_selection.png" /></p>
<!-- <img src='img/forward_selection.png' width="1000" height="1000" /> --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SequentialFeatureSelector</span>

<span class="n">pipe_forward</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">SequentialFeatureSelector</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span> 
                              <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;forward&quot;</span><span class="p">,</span> 
                              <span class="n">n_features_to_select</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> 
                              <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_forward</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       6.934771
score_time     0.008274
test_score     0.933020
train_score    1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_forward</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">SequentialFeatureSelector</span><span class="p">(</span>
        <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span> 
                           <span class="n">direction</span><span class="o">=</span><span class="s2">&quot;backward&quot;</span><span class="p">,</span> 
                           <span class="n">n_features_to_select</span><span class="o">=</span><span class="mi">15</span><span class="p">),</span>
    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_forward</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>fit_time       8.221132
score_time     0.008003
test_score     0.950627
train_score    1.000000
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
<section id="other-ways-to-search">
<h3>Other ways to search<a class="headerlink" href="#other-ways-to-search" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Stochastic local search</p>
<ul>
<li><p>Inject randomness so that we can explore new parts of the search space</p></li>
<li><p>Simulated annealing</p></li>
<li><p>Genetic algorithms</p></li>
</ul>
</li>
</ul>
</section>
<section id="warnings-about-feature-selection">
<h3>Warnings about feature selection<a class="headerlink" href="#warnings-about-feature-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A feature’s relevance is only defined in the context of other features.</p>
<ul>
<li><p>Adding/removing features can make features relevant/irrelevant.</p></li>
</ul>
</li>
<li><p>If features can be predicted from other features, you cannot know which one to pick.</p></li>
<li><p>Relevance for features does not have a causal relationship.</p></li>
<li><p>Don’t be overconfident.</p>
<ul>
<li><p>The methods we have seen probably do not discover the ground truth and how the world really works.</p></li>
<li><p>They simply tell you which features help in predicting <span class="math notranslate nohighlight">\(y_i\)</span> for the data you have.</p></li>
</ul>
</li>
</ul>
</section>
<section id="iclicker-exercise-13-3">
<h3>(iClicker) Exercise 13.3<a class="headerlink" href="#iclicker-exercise-13-3" title="Permalink to this heading">#</a></h3>
<p><strong>iClicker cloud join link: https://join.iclicker.com/3DP5H</strong></p>
<p><strong>Select all of the following statements which are TRUE.</strong></p>
<ul class="simple">
<li><p>(A) Simple association-based feature selection approaches do not take into account the interaction between features.</p></li>
<li><p>(B) You can carry out feature selection using linear models by pruning the features which have very small weights (i.e., coefficients less than a threshold).</p></li>
<li><p>(C) Forward search is guaranteed to find the best feature set.</p></li>
<li><p>(D) The order of features removed given by <code class="docutils literal notranslate"><span class="pre">rfe.ranking_</span></code> is the same as the order of original feature importances given by the model.</p></li>
<li><p>(E) If you remove 10 features in a single step based on feature importance, the same 10 features would be removed if we performed sequential removal calculating feature importance after removing each feature.</p></li>
</ul>
</section>
<section id="optional-problems-with-feature-selection">
<h3>(Optional) Problems with feature selection<a class="headerlink" href="#optional-problems-with-feature-selection" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The term ‘relevance’ is not clearly defined.</p></li>
<li><p>What all things can go wrong with feature selection?</p></li>
<li><p>Attribution: From CPSC 340.</p></li>
</ul>
<section id="example-is-relevance-clearly-defined">
<h4>Example: Is “Relevance” clearly defined?<a class="headerlink" href="#example-is-relevance-clearly-defined" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Consider a supervised classification task of predicting whether someone has particular genetic variation (SNP)</p></li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_mom_dad.png"><img alt="../../_images/sex_mom_dad.png" src="../../_images/sex_mom_dad.png" style="width: 600px; height: 600px;" /></a>
<ul class="simple">
<li><p>True model: You almost have the same value as your biological mom.</p></li>
</ul>
</section>
<section id="is-relevance-clearly-defined">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#is-relevance-clearly-defined" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>True model: You almost have the same value for SNP as your biological mom.</p>
<ul>
<li><p>(SNP = biological mom) with very high probability</p></li>
<li><p>(SNP != biological mom) with very low probability</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/SNP.png"><img alt="../../_images/SNP.png" src="../../_images/SNP.png" style="width: 400px; height: 400px;" /></a>
</section>
<section id="id2">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>What if “mom” feature is repeated?</p></li>
<li><p>Should we pick both? Should we pick one of them because it predicts the other?</p></li>
<li><p>Dependence, collinearity for linear models</p>
<ul>
<li><p>If a feature can be predicted from the other, don’t know which one to pick.</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_mom_mom2_dad.png"><img alt="../../_images/sex_mom_mom2_dad.png" src="../../_images/sex_mom_mom2_dad.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id3">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>What if we add (maternal) “grandma” feature?</p></li>
<li><p>Is it relevant?</p>
<ul>
<li><p>We can predict SNP accurately using this feature</p></li>
</ul>
</li>
<li><p>Conditional independence</p>
<ul>
<li><p>But grandma is irrelevant given biological mom feature</p></li>
<li><p>Relevant features may become irrelevant given other features</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_mom_dad_grandma.png"><img alt="../../_images/sex_mom_dad_grandma.png" src="../../_images/sex_mom_dad_grandma.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id4">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>What if we do not know biological mom feature and we just have grandma feature</p></li>
<li><p>It becomes relevant now.</p>
<ul>
<li><p>Without mom feature this is the best we can do.</p></li>
</ul>
</li>
<li><p>General problem (“taco Tuesday” problem)</p>
<ul>
<li><p>Features can become relevant due to missing information</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_dad_grandma.png"><img alt="../../_images/sex_dad_grandma.png" src="../../_images/sex_dad_grandma.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id5">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Are there any relevant features now?</p></li>
<li><p>They may have some common maternal ancestor.</p></li>
<li><p>What if mom likes dad because they share SNP?</p></li>
<li><p>General problem (Confounding)</p>
<ul>
<li><p>Hidden features can make irrelevant features relevant.</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_dad.png"><img alt="../../_images/sex_dad.png" src="../../_images/sex_dad.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id6">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Now what if we have “sibling” feature?</p></li>
<li><p>The feature is relevant in predicting SNP but not the cause of SNP.</p></li>
<li><p>General problem (non causality)</p>
<ul>
<li><p>the relevant feature may not be causal</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_dad_sibling.png"><img alt="../../_images/sex_dad_sibling.png" src="../../_images/sex_dad_sibling.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id7">
<h4>Is “Relevance” clearly defined?<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>What if you are given “baby” feature?</p></li>
<li><p>Now the sex feature becomes relevant.</p>
<ul>
<li><p>“baby” feature is relevant when sex == F</p></li>
</ul>
</li>
<li><p>General problem (context specific relevance)</p>
<ul>
<li><p>adding a feature can make an irrelevant feature relevant</p></li>
</ul>
</li>
</ul>
<a class="reference internal image-reference" href="../../_images/sex_dad_baby.png"><img alt="../../_images/sex_dad_baby.png" src="../../_images/sex_dad_baby.png" style="width: 600px; height: 600px;" /></a>
</section>
<section id="id8">
<h4>Warnings about feature selection<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>A feature is only relevant in the context of other features.</p>
<ul>
<li><p>Adding/removing features can make features relevant/irrelevant.</p></li>
</ul>
</li>
<li><p>Confounding factors can make irrelevant features the most relevant.</p></li>
<li><p>If features can be predicted from other other features, you cannot know which one to pick.</p></li>
<li><p>Relevance for features does not have a causal relationship.</p></li>
<li><p>Is feature selection completely hopeless?</p>
<ul>
<li><p>It is messy but we still need to do it. So we try to do our best!</p></li>
</ul>
</li>
</ul>
</section>
<section id="relevant-resources">
<h4>Relevant resources<a class="headerlink" href="#relevant-resources" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Genome-wide_association_study">Genome-wide association study</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/feature_selection.html">sklearn feature selection</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=ioXKxulmwVQ">PyData: A Practical Guide to Dimensionality Reduction Techniques</a></p></li>
</ul>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-cpsc330-py"
        },
        kernelOptions: {
            name: "conda-env-cpsc330-py",
            path: "./lectures/slides"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-cpsc330-py'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#announcements">Announcements</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-outcomes">Learning outcomes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering-motivation">Feature engineering: Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iclicker-exercise-13-1">iClicker Exercise 13.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#garbage-in-garbage-out">Garbage in, garbage out.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activity-how-can-you-measure-quality-of-the-data-3-mins">Activity: How can you measure quality of the data? (~3 mins)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-feature-engineering">What is feature engineering?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-quotes-on-feature-engineering">Some quotes on feature engineering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#better-features-usually-help-more-than-a-better-model">Better features usually help more than a better model.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-best-features-may-be-dependent-on-the-model-you-use">The best features may be dependent on the model you use.</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#domain-specific-transformations">Domain-specific transformations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Domain-specific transformations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-interactions-and-feature-crosses">Feature interactions and feature crosses</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-crosses-for-one-hot-encoded-features">Feature crosses for one-hot encoded features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-of-feature-engineering-with-numeric-features">Demo of feature engineering with numeric features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-of-feature-engineering-for-text-data">Demo of feature engineering for text data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baseline">Baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bag-of-words-model">Bag-of-words model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-it-possible-to-further-improve-the-scores">Is it possible to further improve the scores?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spacy">spaCy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-example-from-a-project">An example from a project</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-feature-engineering-for-our-problem">Simple feature engineering for our problem.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interim-summary">Interim summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-engineering">Feature engineering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection-introduction-and-motivation">Feature selection: Introduction and motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-feature-selection">What is feature selection?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-feature-selection">Why feature selection?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-do-we-carry-out-feature-selection">How do we carry out feature selection?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-models-recap">Linear models recap</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression-l2-penalty">Ridge regression (L2 penalty)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso-regression-l1-penalty">Lasso regression (L1 penalty)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-l1-and-l2">Logistic regression (L1 and L2)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#l1-vs-l2-penalty-summary">L1 vs L2 penalty summary</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-based-selection">Model-based selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iclicker-exercise-13-2">(iClicker) Exercise 13.2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recursive-feature-elimination-rfe">Recursive feature elimination (RFE)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rfe-algorithm">RFE algorithm</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-search-and-score">(Optional) Search and score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#general-idea-of-search-and-score-methods">General idea of search and score methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-forward-or-backward-selection">(Optional) Forward or backward selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-ways-to-search">Other ways to search</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warnings-about-feature-selection">Warnings about feature selection</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iclicker-exercise-13-3">(iClicker) Exercise 13.3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-problems-with-feature-selection">(Optional) Problems with feature selection</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-is-relevance-clearly-defined">Example: Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#is-relevance-clearly-defined">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">Is “Relevance” clearly defined?</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">Warnings about feature selection</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-resources">Relevant resources</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>