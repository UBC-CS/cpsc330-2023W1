{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9cc49",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Worksheet_3.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5132b7-52ce-43c7-85c3-4029dc3e74c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Worksheet 3: Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26baf5b-b2dc-44cf-8099-d1af6a70b721",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This worksheet is intended to help you revise and reinforce what you've learnt in the lecture.\n",
    "</br>Please fill in the answers, or write the code, in the space provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8ed3b-01fa-48bb-ba67-fabf7e7b15c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac3f62-9694-4354-bc77-81a397d1a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8875ca-d459-41ad-84c9-cee0bddd324d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1: Preprocessing the Spotify dataset \n",
    "\n",
    "\n",
    "Remember Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset from homework 1? The dataset contains a number of features of songs from 2017 and a binary variable `target` that represents whether the user liked the song (encoded as 1) or not (encoded as 0). See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/). \n",
    "\n",
    "In homework 1, all features that appeared numeric were treated as such, while text features were dropped. This approach was taken primarily to keep things simple and familiarize you with basic `sklearn` syntax. However, with a wider range of tools available now, it's time to reconsider the different feature types and potential transformations within this dataset.\n",
    "\n",
    "The code below reads the dataset and splits it, assuming that it's located in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957782e-f5f5-4398-8e09-85b3b96ab2d8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"data/spotify.csv\", index_col=0)\n",
    "X_spotify = spotify_df.drop(columns=[\"target\"])\n",
    "y_spotify = spotify_df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_spotify, y_spotify, test_size=0.2, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00b1a0-ff92-4910-8dea-05e5681f01d3",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f982b15-4200-4720-b830-c611a873a4fa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.1 Dummy model\n",
    "rubric={points}\n",
    "\n",
    "- Obtain the mean cross validation score using the dummy model and store it in the variable `dummy_mean_cv_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fb168-b57e-4575-a364-b639320a426e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56880f4f-28ab-4b9c-9f60-1cdcec8b9131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_mean_cv_score = None \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d932c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1fe776-8ade-404a-9f9e-4fabed06d49d",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc0b79-6f15-441f-bb2b-593c26fd6143",
   "metadata": {},
   "source": [
    "### Feature categories and transformations \n",
    "\n",
    "- Examine the value counts of the following features and refer to [the documentation](https://developer.spotify.com/documentation/web-api/reference/get-audio-features) for these features:\n",
    "    - `time_signature`\n",
    "    - `mode`\n",
    "    - `key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb6719-560c-411e-bba2-1d01475d189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['time_signature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc66ad-1d19-415a-96bf-81336ba80b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e3698-5522-4534-b9f1-9a8bcd1877a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['key'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff372ab-9bed-4e36-823b-2f3516017b5e",
   "metadata": {},
   "source": [
    "Do you think these features should be treated as numeric features? \n",
    "\n",
    "Consider the following categorization of features and discuss with your neighbour whether it makes sense or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775af965-c75e-4824-a0ca-c5f4fae64ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = ['acousticness', 'danceability', 'energy',\n",
    "                 'instrumentalness', 'liveness', 'loudness',\n",
    "                 'speechiness', 'tempo', 'valence']\n",
    "categorical_feats = ['time_signature', 'key']\n",
    "passthrough_feats = ['mode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f040c070-b60e-4532-aec5-99cf1ca49538",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6e9350-3345-4751-a38f-47042772d4f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.2 Only numeric features\n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate the mean cross-validation score using only the `numeric_feats`. \n",
    "1. In particular, create a pipeline with two steps:\n",
    "    - Step 1: Apply StandardScaler() with default hyperparameters to scale the numeric features.\n",
    "    - Step 2: Use SVC() with default hyperparameters as the estimator.\n",
    "2. Compute the mean cross-validation score with the pipeline described above and store it in the variable `num_mean_cv_score` as indicated below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827eb29-2773-4a8e-bab7-e1e0316dc645",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f135910-b2f4-49d7-adba-f2a2ba10dcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_mean_cv_score = None \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a8034-2fe1-4ad1-b5c8-71901ffcccbb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "num_mean_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c800ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb7932-f6ae-42b3-89e8-ac8373067b3b",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dc3d56-6401-4fdd-aabf-9e2b60641f84",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.3 Numeric + categorical + passthrough features \n",
    "rubric={points}\n",
    "\n",
    "Next, incorporate both categorical and passthrough features into the pipeline. Begin by defining a column transformer named `preprocessor` with distinct transformations for various feature categories:\n",
    "\n",
    "- Apply `StandardScaler` to numeric_feats.\n",
    "- Use `OneHotEncoder` with `handle_unknown = \"ignore\"` for categorical_feats.\n",
    "- Keep `passthrough_feats` unchanged by specifying \"passthrough\".\n",
    "\n",
    "Following this, create a pipeline named `svc_pipe` with preprocessor as the initial step and `SVC()` as the chosen estimator. Calculate the mean cross-validation score and store it in the variable `num_cat_mean_cv_score` below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6020854-702b-4bca-8676-1a82c06fcbc8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d43ff-2854-42e8-9f3c-3639838cc722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cat_mean_cv_score = None \n",
    "preprocessor = None\n",
    "svc_pipe = None \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21fabe7-4daf-4787-a8cd-f43524b6e3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cat_mean_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef712c1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd4612-c4cf-45c7-921a-a55e16787048",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfbe9c2-63a7-47bb-a6db-05ea4aec8c61",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.4 Incorporating text features\n",
    "rubric={points}\n",
    "\n",
    "Remember that in homework 2, the song_title feature was excluded when working with this dataset. However, this feature can be valuable for our prediction task.\n",
    "\n",
    "Let's incorporate it into our pipeline by applying a bag-of-words representation to the feature. Define a column transformer called `preprocessor` with the following transformations for different feature categories:\n",
    "\n",
    "- `StandardScaler` on `numeric_feats`.\n",
    "- `OneHotEncoder` on `categorical_feats`. (Pass `handle_unknown = \"ignore\"`.)\n",
    "- `\"passthrough\"` for `passthrough_feats`.\n",
    "- `CountVectorizer` with `max_features=50` and `stop_words=\"english\"` on the `song_title` feature.\n",
    "  \n",
    "Then, create a pipeline named `svc_all_pipe` with `preprocessor` as the first step and `SVC()` as the estimator. Calculate the mean cross-validation score and store it in the variable `all_mean_cv_score` below.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Recall that you had dropped `song_title` feature in homework 2 when you worked with this dataset. But this feature can be useful for this prediction task\n",
    "\n",
    "Include it in our pipeline by applying bag-of-words representation on the feature. So define a column transformer called `preprocessor` with the following transformations on different feature categories. \n",
    "- `StandardScaler` on `numeric_feats`\n",
    "- `OneHotEncoder` on `categorical_feats` \n",
    "- `\"passthrough\"` the `passthrough_fets`\n",
    "- `CountVectorizer` with `max_features=50` and `stop_words=\"english\"` on `song_title` feature\n",
    "\n",
    "Then define a pipeline `svc_all_pipe` with `preprocessor` as the first step and `SVC()` as the estimator. Get the mean cross validation score and store it in the variable `all_mean_cv_score` below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df288a-388f-44cb-8060-7a7a492f82e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.4\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12331f0-f50c-407c-8b68-352d4981a77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_mean_cv_score = None \n",
    "svc_all_pipe = None\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4dace9-dd43-4bab-964b-3ea68d882cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_mean_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf2a8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31012893-6c53-49ee-b37f-70b9734c1bfe",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29afe6b-0b96-489f-9c40-2fccd156eb84",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1.5 Test scores \n",
    "rubric={points}\n",
    "\n",
    "Now, let's fit `svc_all_pipe` to the complete `X_train` and `y_train`, and evaluate its performance on `X_test` and `y_test`. Store these evaluation scores in the `test_score` variable below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55974c-ad18-4778-b615-357c31752afe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1.5\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8da22a-d0df-4839-838f-aaecd147c2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_score = None \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e7e36",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd72dc-a871-4102-a22e-60ae07d9e3c1",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa132b3-4a3b-400f-97af-3a4412e5dccb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "ðŸ”Ž **Challenge:** Explore the vocabulary created by `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9840fff-a5ac-4173-8e21-b1289c19f6b4",
   "metadata": {},
   "source": [
    "ðŸ”Ž **Challenge:** Incorporate the `artist` feature in the pipeline. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "cpsc330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(np.round(dummy_mean_cv_score, 2)).encode('utf-8')).hexdigest() == '9052a7647b871a28786a7fb5f57c6c01ad200a17', 'Are you calculating the mean of the cross-validation scores?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(np.round(num_mean_cv_score, 2)).encode('utf-8')).hexdigest() == 'a534e76482ade9d9fe4bff3035a7f31f2f363d77', 'Are you calculating the mean of the cross-validation scores?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3": {
     "name": "q1.3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(np.round(num_cat_mean_cv_score, 3)).encode('utf-8')).hexdigest() == 'd3cfc70f16f60af083ddef65aa44775d51bbefe5', 'Are you calculating the mean of the cross-validation scores?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4": {
     "name": "q1.4",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(np.round(all_mean_cv_score, 3)).encode('utf-8')).hexdigest() == '312d36b31e5b718b01e4880a5fe33b229b5261ae', 'Are you calculating the mean of the cross-validation scores?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.5": {
     "name": "q1.5",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert sha1(str(np.round(test_score, 2)).encode('utf-8')).hexdigest() == '0cf1aeac0372e10da230a32e74c9b6e68dca7342', 'Are you calculating the mean of the cross-validation scores?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
