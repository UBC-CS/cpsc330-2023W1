{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800abc6f-4f8a-4a21-97bc-691a0d58d8d2",
   "metadata": {},
   "source": [
    "# Appendix A: Common features used in text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684bf39a-47b4-4942-b456-1ee8311a3f36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of words \n",
    "\n",
    "- So far for text data we have been using bag of word features. \n",
    "- They are good enough for many tasks. But ... \n",
    "- This encoding throws out a lot of things we know about language\n",
    "- It assumes that word order is not that important.   \n",
    "- So if you want to improve the scores further on text classification tasks you carry out **feature engineering**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb9a58-8fbc-4e44-a6fa-02f87daa4dc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at some examples from research papers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4953db55-5b17-4609-84f8-7e85d891d128",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Label \"Personalized\" Important E-mails: \n",
    "- [The Learning Behind Gmail Priority Inbox](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf)\n",
    "- Features: bag of words, trigrams, regular expressions, and so on.\n",
    "- There might be some \"globally\" important messages:\n",
    "    - \"This is your mother, something terrible happened, give me a call ASAP.\"\n",
    "- But your \"important\" message may be unimportant to others.\n",
    "     - Similar for spam: \"spam\" for one user could be \"not spam\" for another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff195562-6250-4692-8b0d-e4b018a282a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Social features (e.g., percentage of sender emails that is read by the recipient)\n",
    "- Content features (e.g., recent terms the user has been using in emails)\n",
    "- Thread features (e.g., whether the user has started the thread)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8f384f-6fbc-494f-a5f7-0d18a1911cc3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### [The Learning Behind Gmail Priority Inbox](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36955.pdf)\n",
    "\n",
    "![](img/gmail_priority_inbox.png)\n",
    "\n",
    "<!-- <img src=\"img/gmail_priority_inbox.png\" width=\"1000\" height=\"1000\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50b53a-f581-4adb-aabb-11dee03e6bb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Feature engineering examples: [Automatically Identifying Good Conversations Online](http://www.courtneynapoles.com/res/icwsm17-automatically.pdf)\n",
    "\n",
    "![](img/classifying_good_conversations_online.png)\n",
    "\n",
    "<!-- <img src=\"img/classifying_good_conversations_online.png\" width=\"800\" height=\"800\"> -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5798641-8cd4-46e3-b8ee-14016ffa2b29",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Term weighing (TF-IDF) \n",
    "\n",
    "- A measure of relatedness between words and documents\n",
    "- Intuition: Meaningful words may occur repeatedly in related documents, but functional words (e.g., _make_, _the_) may be distributed evenly over all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39f7ba-213e-45a2-a8f8-529d27f8fa53",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "$$tf.idf(w_i,d_j) = (1+log(tf_{ij})) log\\frac{D}{df_i}$$\n",
    "\n",
    "\n",
    "where, \n",
    "- $tf_{ij}$ &rarr; number of occurrences of the term $w_i$ in document $d_j$\n",
    "- $D$ &rarr; number of documents\n",
    "- $df_i$ &rarr; number of documents in which $w_i$ occurs\n",
    "\n",
    "Check `TfidfVectorizer` from `sklearn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e0e5b-ee23-40ec-bea8-6aa31aed1a92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### N-grams \n",
    "\n",
    "- Incorporating more context \n",
    "- A contiguous sequence of _n_ items (characters, tokens) in text.\n",
    "    <blockquote>\n",
    "        CPSC330 students are hard-working .\n",
    "    </blockquote>    \n",
    "\n",
    "- 2-grams (bigrams): a contiguous sequence of two words\n",
    "    * _CPSC330 students, students are, are hard-working, hard-working ._\n",
    "- 3-grams (trigrams): a contiguous sequence of three words\n",
    "    * _CPSC330 students are, students are hard-working, are hard-working ._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f6b13-ea55-4397-8e8a-21e000553482",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can extract ngram features using `CountVectorizer` by passing `ngram_range`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08876202-129c-4898-9494-4a43aa844e09",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X = [\n",
    "    \"URGENT!! As a valued network customer you have been selected to receive a $900 prize reward!\",\n",
    "    \"Lol you are always so convincing.\",\n",
    "    \"URGENT!! Call right away!!\",\n",
    "]\n",
    "vec = CountVectorizer(ngram_range=(1, 3))\n",
    "X_counts = vec.fit_transform(X)\n",
    "bow_df = pd.DataFrame(X_counts.toarray(), columns=vec.get_feature_names_out().tolist(), index=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f56678-7ec4-4a57-a526-c53955bcfb8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeca6c6-879e-4a90-a6a7-3f701b94fb60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ASIDE: [Google n-gram viewer](https://books.google.com/ngrams)\n",
    " \n",
    "- All Our N-gram are Belong to You\n",
    "    - https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-toyou.html\n",
    "\n",
    "<blockquote>\n",
    "Here at Google Research we have been using word n-gram models for a variety\n",
    "of R&D projects, such as statistical machine translation, speech recognition,\n",
    "spelling correction, entity detection, information extraction, and others.\n",
    "That's why we decided to share this enormous dataset with everyone. We\n",
    "processed 1,024,908,267,229 words of running text and are publishing the\n",
    "counts for all 1,176,470,663 five-word sequences that appear at least 40\n",
    "times. There are 13,588,391 unique words, after discarding words that appear\n",
    "less than 200 times.‚Äù\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e21e5-4aac-45e4-8843-3f4ed96b2e86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "url = \"https://books.google.com/ngrams/\"\n",
    "HTML(\"<iframe src=%s width=1000 height=800></iframe>\" % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a793e-3828-4def-aafc-fa5092c7777d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: [Google n-gram viewer](https://books.google.com/ngrams)\n",
    " \n",
    "- Count the occurrences of the bigram _smart women_ in the corpus from 1800 to 2000 \n",
    "\n",
    "![](img/ngram_viewer_smart_woman.png)\n",
    "\n",
    "<!-- <img src=\"img/ngram_viewer_smart_woman.png\" width=\"800\" height=\"800\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d9224-24d3-4b50-b9c0-e5e2a2a06798",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Aside: [Google n-gram viewer](https://books.google.com/ngrams)\n",
    " \n",
    "- Trends in the word _challenge_ used as a noun vs. verb\n",
    "\n",
    "![](img/ngram_viewer_challenge_NN_VB.png)\n",
    "\n",
    "<!-- <img src=\"img/ngram_viewer_challenge_NN_VB.png\" width=\"800\" height=\"800\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9e30e-0acd-4beb-ab52-d62e2f493f33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part-of-speech features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e353b9e-4397-4d93-b296-a1c282623689",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Part-of-speech (POS) in English\n",
    "\n",
    "- Part-of-speech: A kind of syntactic category that tells you some of the grammatical properties of a word.\n",
    "    * Noun &rarr; water, sun, cat  \n",
    "    * Verb &rarr; run, eat, teach\n",
    "\n",
    "    \n",
    "<blockquote>\n",
    "The ____ was running. \n",
    "</blockquote>    \n",
    "\n",
    "- Only a noun fits here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e85d89-1ad5-4390-9e62-97b7a26150a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Part-of-speech (POS) features\n",
    "\n",
    "- POS features use POS information for the words in text.  \n",
    "\n",
    "<blockquote>\n",
    "    CPSC330/<span style=\"color:green\">PROPER_NOUN</span> students/<span style=\"color:green\">NOUN</span> are/<span style=\"color:green\">VERB</span> hard-working/<span style=\"color:green\">ADJECTIVE</span>\n",
    "</blockquote>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8be07-0d6f-472b-950c-5cf229aa4a21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An example from a project \n",
    "\n",
    "- Data: a bunch of documents \n",
    "- Task: identify texts with *permissions* and identify who is giving permission to whom. \n",
    "\n",
    "<blockquote>\n",
    "<b>You</b> may <b>disclose</b> Google confidential information when compelled to do so by law if <b>you</b> provide <b>us</b> reasonable prior notice, unless a court orders that <b>we</b> not receive notice.\n",
    "</blockquote>\n",
    "\n",
    "- A very simple solution\n",
    "    * Look for pronouns and verbs. \n",
    "    * Add POS tags as features in your model. \n",
    "    * Maybe look up words similar to **disclose**.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090028a-5899-46cc-9b76-d3ece02a4160",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Penn Treebank part-of-speech tags (bonus)\n",
    "\n",
    "![](img/PTB_POS.png)\n",
    "\n",
    "<!-- <img src=\"img/PTB_POS.png\" width=\"900\" height=\"900\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0eabeb-1fee-4f75-8409-e027cfb88a9d",
   "metadata": {},
   "source": [
    "- You also need to download the language model which contains all the pre-trained models. For that run the following in your course `conda` environment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "cpsc330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
