{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(\"..\"), \"code\"))\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from plotting_functions import *\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, classification_report, f1_score, precision_recall_curve, roc_auc_score, roc_curve, ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f009286",
   "metadata": {},
   "source": [
    "# Exploring classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e53c3",
   "metadata": {},
   "source": [
    "### Dataset for demonstration \n",
    "\n",
    "Let's classify fraudulent and non-fraudulent transactions using Kaggle's [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812c9f03",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ada15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df = pd.read_csv(\"../data/creditcard.csv\", encoding=\"latin-1\")\n",
    "train_df, test_df = train_test_split(cc_df, test_size=0.3, random_state=111)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_big, y_train_big = train_df.drop(columns=[\"Class\", \"Time\"]), train_df[\"Class\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"Class\", \"Time\"]), test_df[\"Class\"]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_big, y_train_big, test_size=0.6, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56208d5e",
   "metadata": {},
   "source": [
    "## Comparing PR curves\n",
    "\n",
    "Let's create PR curves for SVC and Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c34625",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a76afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677529c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_lr, recall_lr, thresholds_lr = precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8824998",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d83c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_svc, recall_svc, thresholds_svc = precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(precision_svc, recall_svc, label=\"SVC\")\n",
    "plt.plot(precision_lr, recall_lr, label=\"Logistic regression\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e25ca",
   "metadata": {},
   "source": [
    "### Let's look at the F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddff655",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_f1 = None\n",
    "svc_f1 = None\n",
    "\n",
    "print(lr_f1, svc_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff6bbd",
   "metadata": {},
   "source": [
    "### What about the average precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ap = None\n",
    "svc_ap = None\n",
    "\n",
    "print(lr_ap, svc_ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c0dea",
   "metadata": {},
   "source": [
    "## Comparing ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab105de",
   "metadata": {},
   "source": [
    "Let's look at the ROC curve for Logistic Regression first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825ea26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "886bcbb1",
   "metadata": {},
   "source": [
    "But what if we want to plot more than one classifier? Let's look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_estimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224dfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "117fe572",
   "metadata": {},
   "source": [
    "## Comparing class_weight\n",
    "\n",
    "Let's explore how the `class_weight` argument impacts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f957b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard LogisticRegression\n",
    "pipe_lr_std = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving a weight of 1 to the non-fraud and 10 to fraud examples\n",
    "pipe_lr_upw ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68febcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced weights\n",
    "pipe_lr_balanced ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deef9b1",
   "metadata": {},
   "source": [
    "First let's look at the precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88aff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7c38fa0",
   "metadata": {},
   "source": [
    "Now let's consider the ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cc1ac51",
   "metadata": {},
   "source": [
    "# ML fairness activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84d6ef",
   "metadata": {},
   "source": [
    "AI/ML systems can give the illusion of objectivity as they are derived from seemingly unbiased data & algorithm. However, human are inherently biased and AI/ML systems, if not carefully evaluated, can even further amplify the existing inequities and systemic bias in our society.  \n",
    "\n",
    "How do we make sure our AI/ML systems are *fair*? Which metrics can we use to quatify 'fairness' in AI/ML systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b6c52",
   "metadata": {},
   "source": [
    "### Dataset for demonstration \n",
    "\n",
    "Let's examine this on [the adult census data set](https://www.kaggle.com/uciml/adult-census-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ebaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_df = pd.read_csv(\"../data/adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079efcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(census_df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5989357",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.nan)\n",
    "test_df_nan = test_df.replace(\"?\", np.nan)\n",
    "train_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c44140",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\",\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"workclass\",\n",
    "    \"marital.status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"native.country\",\n",
    "]\n",
    "\n",
    "ordinal_features = [\"education\"]\n",
    "binary_features = [\n",
    "    \"sex\"\n",
    "]  # Not binary in general but in this particular dataset it seems to have only two possible values\n",
    "drop_features = [\"education.num\", \"fnlwgt\"]\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18c8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"education\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_levels = [\n",
    "    \"Preschool\",\n",
    "    \"1st-4th\",\n",
    "    \"5th-6th\",\n",
    "    \"7th-8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"11th\",\n",
    "    \"12th\",\n",
    "    \"HS-grad\",\n",
    "    \"Prof-school\",\n",
    "    \"Assoc-voc\",\n",
    "    \"Assoc-acdm\",\n",
    "    \"Some-college\",\n",
    "    \"Bachelors\",\n",
    "    \"Masters\",\n",
    "    \"Doctorate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a80052",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(education_levels) == set(train_df[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns=[target])\n",
    "y_train = train_df_nan[target]\n",
    "\n",
    "X_test = test_df_nan.drop(columns=[target])\n",
    "y_test = test_df_nan[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4905455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "ordinal_transformer = OrdinalEncoder(categories=[education_levels], dtype=int)\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer, ordinal_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3066fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c818d",
   "metadata": {},
   "source": [
    "Let's build our classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca55924",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721814c",
   "metadata": {},
   "source": [
    "And look at the confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c2aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5017ab07",
   "metadata": {},
   "source": [
    "Let's examine confusion matrix separately for the two genders we have in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "preprocessor.named_transformers_[\"pipeline-2\"][\"onehotencoder\"].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d17b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_female = X_test.query(\"sex=='Female'\")  # X where sex is female\n",
    "X_male = X_test.query(\"sex=='Male'\")  # X where sex is male\n",
    "\n",
    "y_female = y_test[X_female.index]  # y where sex is female\n",
    "y_male = y_test[X_male.index]  # y where sex is male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c407bb57",
   "metadata": {},
   "source": [
    "**Get predictions for `X_female` and `y_male` with `pipe_lr`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_preds = pipe_lr.predict(X_female)\n",
    "male_preds = pipe_lr.predict(X_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5cc0c",
   "metadata": {},
   "source": [
    "Let's examine the accuracy and confusion matrix for female class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_female, female_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae317d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_lr, X_female, y_female, normalize=\"true\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7c209",
   "metadata": {},
   "source": [
    "Let's examine the accuracy and confusion matrix for male class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_male, male_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(pipe_lr, X_male, y_male, normalize=\"true\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746017d",
   "metadata": {},
   "source": [
    "### ❓❓ Questions for group discussion\n",
    "\n",
    "Let's assume that a company is using this classifier for loan approval with a simple rule that if the income is >=50K, approve the loan else reject the loan. \n",
    "\n",
    "In your group, discuss the questions below and write the main points from your discussion in this [Google document](https://docs.google.com/document/d/1nsOsdO-zRwvWWwM4-6h2t7eHgIhW8FCy3ebxoT7p0HY/edit?usp=sharing). \n",
    "\n",
    "1. Which group has a higher accuracy?\n",
    "2. Which group has a higher precision for class >50K? What about recall for class >50K?\n",
    "3. Will both groups have more or less the same proportion of people with approved loans? \n",
    "4. If a male and a female have both a certain level of income, will they have the same chance of getting the loan?\n",
    "5. Banks want to avoid approving unqualified applications (false positives) because default loan could have detrimental effects for them. Compare the false positive rates for the two groups.    \n",
    "6. Overall, do you think this income classifier will fairly treat both groups? What will be the consequences of using this classifier in loan approval application? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b6fa7",
   "metadata": {},
   "source": [
    "**Time permitting**\n",
    "1. Do you think the effect will still exist if the sex feature is removed from the model (but you still have it available separately to do the two confusion matrices)? \n",
    "2. Are there any other groups in this dataset worth examining for biases? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-cpsc330-py",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
