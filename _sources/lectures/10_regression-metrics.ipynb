{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](img/330-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lecture 10: Regression metrics\n",
    "\n",
    "UBC, 2023-24\n",
    "\n",
    "Instructor: Varada Kolhatkar and Andrew Roth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    TransformedTargetRegressor,\n",
    "    make_column_transformer,\n",
    ")\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Announcements \n",
    "\n",
    "- HW4 is due tonight. \n",
    "- HW5 will be posted today. It is a project-type homework assignment and will be due after the midterm.  \n",
    "- Midterm: Thursday, October 26th, 2023 at 6:00pm (~75 mins long)\n",
    "    - Checkout the midterm information announcement on Piazza (@407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes \n",
    "\n",
    "From this lecture, students are expected to be able to:\n",
    "\n",
    "- Carry out feature transformations on somewhat complicated dataset. \n",
    "- Visualize transformed features as a dataframe. \n",
    "- Use `Ridge` and `RidgeCV`.\n",
    "- Explain how `alpha` hyperparameter of `Ridge` relates to the fundamental tradeoff. \n",
    "- Explain the effect of `alpha` on the magnitude of the learned coefficients. \n",
    "- Examine coefficients of transformed features.  \n",
    "- Appropriately select a scoring metric given a regression problem.\n",
    "- Interpret and communicate the meanings of different scoring metrics on regression problems.\n",
    "    - MSE, RMSE, $R^2$, MAPE\n",
    "- Apply log-transform on the target values in a regression problem with `TransformedTargetRegressor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After carrying out preprocessing, why it's useful to get feature names for transformed features?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More comments on tackling class imbalance\n",
    "\n",
    "- In lecture 9 we talked about a few rather simple approaches to deal with class imbalance. \n",
    "- If you have a problem such as fraud detection problem where you want to spot rare events, you can also think of this problem as anomaly detection problem and use different kinds of algorithms such as [isolation forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html).  \n",
    "- If you are interested in this area, it might be worth checking out this book on this topic.\n",
    "[Imbalanced Learning: Foundations, Algorithms, and Applications](https://www.amazon.com/dp/1118074629/ref=as_li_ss_tl?&linkCode=sl1&tag=inspiredalgor-20&linkId=615e87a9105582e292ad2b7e2c7ea339&language=en_US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note} \n",
    "When you calculate precision, recall, f1 score, by default only the positive label is evaluated, assuming by default that the positive class is labeled 1. This is configurable through the `pos_label` parameter. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset [[video](https://youtu.be/lgGTKLwNgkQ)]\n",
    "\n",
    "In this lecture, we'll be using [Kaggle House Prices dataset](https://www.kaggle.com/c/home-data-for-ml-course/). As usual, to run this notebook you'll need to download the data. For this dataset, train and test have already been separated. We'll be working with the train portion in this lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>303</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>768</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12508</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>1300</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>430</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11457</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1140</td>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8731</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>559</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21872</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "302    303          20       RL        118.0    13704   Pave   NaN      IR1   \n",
       "767    768          50       RL         75.0    12508   Pave   NaN      IR1   \n",
       "429    430          20       RL        130.0    11457   Pave   NaN      IR1   \n",
       "1139  1140          30       RL         98.0     8731   Pave   NaN      IR1   \n",
       "558    559          60       RL         57.0    21872   Pave   NaN      IR2   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "302          Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "767          Lvl    AllPub  ...        0    NaN   NaN        Shed    1300   \n",
       "429          Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "1139         Lvl    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "558          HLS    AllPub  ...        0    NaN   NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "302       1   2006        WD         Normal     205000  \n",
       "767       7   2008        WD         Normal     160000  \n",
       "429       3   2009        WD         Normal     175000  \n",
       "1139      5   2007        WD         Normal     144000  \n",
       "558       8   2008        WD         Normal     175000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/housing-kaggle/train.csv\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.10, random_state=123)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The supervised machine learning problem is predicting housing price given features associated with properties. \n",
    "- Here, the target is `SalePrice`, which is continuous. So it's a **regression problem** (as opposed to classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Let's separate `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"SalePrice\"])\n",
    "y_train = train_df[\"SalePrice\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"SalePrice\"])\n",
    "y_test = test_df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1307.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "      <td>1314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>734.182648</td>\n",
       "      <td>56.472603</td>\n",
       "      <td>69.641873</td>\n",
       "      <td>10273.261035</td>\n",
       "      <td>6.076104</td>\n",
       "      <td>5.570015</td>\n",
       "      <td>1970.995434</td>\n",
       "      <td>1984.659056</td>\n",
       "      <td>102.514155</td>\n",
       "      <td>441.425419</td>\n",
       "      <td>...</td>\n",
       "      <td>94.281583</td>\n",
       "      <td>45.765601</td>\n",
       "      <td>21.726788</td>\n",
       "      <td>3.624049</td>\n",
       "      <td>13.987062</td>\n",
       "      <td>3.065449</td>\n",
       "      <td>46.951294</td>\n",
       "      <td>6.302131</td>\n",
       "      <td>2007.840183</td>\n",
       "      <td>179802.147641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>422.224662</td>\n",
       "      <td>42.036646</td>\n",
       "      <td>23.031794</td>\n",
       "      <td>8997.895541</td>\n",
       "      <td>1.392612</td>\n",
       "      <td>1.112848</td>\n",
       "      <td>30.198127</td>\n",
       "      <td>20.639754</td>\n",
       "      <td>178.301563</td>\n",
       "      <td>459.276687</td>\n",
       "      <td>...</td>\n",
       "      <td>125.436492</td>\n",
       "      <td>65.757545</td>\n",
       "      <td>60.766423</td>\n",
       "      <td>30.320430</td>\n",
       "      <td>53.854129</td>\n",
       "      <td>42.341109</td>\n",
       "      <td>522.283421</td>\n",
       "      <td>2.698206</td>\n",
       "      <td>1.332824</td>\n",
       "      <td>79041.260572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>369.250000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>1966.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>735.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9391.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>162000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1099.750000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11509.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>704.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>66.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>212975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1378.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1314.000000  1314.000000  1089.000000    1314.000000  1314.000000   \n",
       "mean    734.182648    56.472603    69.641873   10273.261035     6.076104   \n",
       "std     422.224662    42.036646    23.031794    8997.895541     1.392612   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     369.250000    20.000000    59.000000    7500.000000     5.000000   \n",
       "50%     735.500000    50.000000    69.000000    9391.000000     6.000000   \n",
       "75%    1099.750000    70.000000    80.000000   11509.000000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1314.000000  1314.000000   1314.000000  1307.000000  1314.000000  ...   \n",
       "mean      5.570015  1970.995434   1984.659056   102.514155   441.425419  ...   \n",
       "std       1.112848    30.198127     20.639754   178.301563   459.276687  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1953.000000   1966.250000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1972.000000   1993.000000     0.000000   376.000000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   165.500000   704.750000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1378.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1314.000000  1314.000000    1314.000000  1314.000000  1314.000000   \n",
       "mean     94.281583    45.765601      21.726788     3.624049    13.987062   \n",
       "std     125.436492    65.757545      60.766423    30.320430    53.854129   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    24.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    66.750000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1314.000000   1314.000000  1314.000000  1314.000000    1314.000000  \n",
       "mean      3.065449     46.951294     6.302131  2007.840183  179802.147641  \n",
       "std      42.341109    522.283421     2.698206     1.332824   79041.260572  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129600.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  162000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  212975.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1314 entries, 302 to 1389\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1314 non-null   int64  \n",
      " 1   MSSubClass     1314 non-null   int64  \n",
      " 2   MSZoning       1314 non-null   object \n",
      " 3   LotFrontage    1089 non-null   float64\n",
      " 4   LotArea        1314 non-null   int64  \n",
      " 5   Street         1314 non-null   object \n",
      " 6   Alley          81 non-null     object \n",
      " 7   LotShape       1314 non-null   object \n",
      " 8   LandContour    1314 non-null   object \n",
      " 9   Utilities      1314 non-null   object \n",
      " 10  LotConfig      1314 non-null   object \n",
      " 11  LandSlope      1314 non-null   object \n",
      " 12  Neighborhood   1314 non-null   object \n",
      " 13  Condition1     1314 non-null   object \n",
      " 14  Condition2     1314 non-null   object \n",
      " 15  BldgType       1314 non-null   object \n",
      " 16  HouseStyle     1314 non-null   object \n",
      " 17  OverallQual    1314 non-null   int64  \n",
      " 18  OverallCond    1314 non-null   int64  \n",
      " 19  YearBuilt      1314 non-null   int64  \n",
      " 20  YearRemodAdd   1314 non-null   int64  \n",
      " 21  RoofStyle      1314 non-null   object \n",
      " 22  RoofMatl       1314 non-null   object \n",
      " 23  Exterior1st    1314 non-null   object \n",
      " 24  Exterior2nd    1314 non-null   object \n",
      " 25  MasVnrType     528 non-null    object \n",
      " 26  MasVnrArea     1307 non-null   float64\n",
      " 27  ExterQual      1314 non-null   object \n",
      " 28  ExterCond      1314 non-null   object \n",
      " 29  Foundation     1314 non-null   object \n",
      " 30  BsmtQual       1280 non-null   object \n",
      " 31  BsmtCond       1280 non-null   object \n",
      " 32  BsmtExposure   1279 non-null   object \n",
      " 33  BsmtFinType1   1280 non-null   object \n",
      " 34  BsmtFinSF1     1314 non-null   int64  \n",
      " 35  BsmtFinType2   1280 non-null   object \n",
      " 36  BsmtFinSF2     1314 non-null   int64  \n",
      " 37  BsmtUnfSF      1314 non-null   int64  \n",
      " 38  TotalBsmtSF    1314 non-null   int64  \n",
      " 39  Heating        1314 non-null   object \n",
      " 40  HeatingQC      1314 non-null   object \n",
      " 41  CentralAir     1314 non-null   object \n",
      " 42  Electrical     1313 non-null   object \n",
      " 43  1stFlrSF       1314 non-null   int64  \n",
      " 44  2ndFlrSF       1314 non-null   int64  \n",
      " 45  LowQualFinSF   1314 non-null   int64  \n",
      " 46  GrLivArea      1314 non-null   int64  \n",
      " 47  BsmtFullBath   1314 non-null   int64  \n",
      " 48  BsmtHalfBath   1314 non-null   int64  \n",
      " 49  FullBath       1314 non-null   int64  \n",
      " 50  HalfBath       1314 non-null   int64  \n",
      " 51  BedroomAbvGr   1314 non-null   int64  \n",
      " 52  KitchenAbvGr   1314 non-null   int64  \n",
      " 53  KitchenQual    1314 non-null   object \n",
      " 54  TotRmsAbvGrd   1314 non-null   int64  \n",
      " 55  Functional     1314 non-null   object \n",
      " 56  Fireplaces     1314 non-null   int64  \n",
      " 57  FireplaceQu    687 non-null    object \n",
      " 58  GarageType     1241 non-null   object \n",
      " 59  GarageYrBlt    1241 non-null   float64\n",
      " 60  GarageFinish   1241 non-null   object \n",
      " 61  GarageCars     1314 non-null   int64  \n",
      " 62  GarageArea     1314 non-null   int64  \n",
      " 63  GarageQual     1241 non-null   object \n",
      " 64  GarageCond     1241 non-null   object \n",
      " 65  PavedDrive     1314 non-null   object \n",
      " 66  WoodDeckSF     1314 non-null   int64  \n",
      " 67  OpenPorchSF    1314 non-null   int64  \n",
      " 68  EnclosedPorch  1314 non-null   int64  \n",
      " 69  3SsnPorch      1314 non-null   int64  \n",
      " 70  ScreenPorch    1314 non-null   int64  \n",
      " 71  PoolArea       1314 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          259 non-null    object \n",
      " 74  MiscFeature    50 non-null     object \n",
      " 75  MiscVal        1314 non-null   int64  \n",
      " 76  MoSold         1314 non-null   int64  \n",
      " 77  YrSold         1314 non-null   int64  \n",
      " 78  SaleType       1314 non-null   object \n",
      " 79  SaleCondition  1314 non-null   object \n",
      " 80  SalePrice      1314 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 841.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `pandas_profiler`\n",
    "\n",
    "We do not have `pandas_profiling` in our course environment. You will  have to install it in the environment on your own if you want to run the code below. \n",
    "\n",
    "```conda install -c conda-forge pandas-profiling```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e74663943c452096d57cdba3ee4598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b3/g26r0dcx4b35vf3nk31216hc0000gr/T/ipykernel_10768/69711575.py\", line 3, in <module>\n",
      "    profile.to_widgets()\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 516, in to_widgets\n",
      "    display(self.widgets)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 289, in widgets\n",
      "    isinstance(self.description_set.table[\"n\"], list)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 253, in description_set\n",
      "    self._description_set = describe_df(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/model/describe.py\", line 130, in describe\n",
      "    scatter_matrix[x][y] = progress(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/utils/progress_bar.py\", line 11, in inner\n",
      "    ret = fn(*args, **kwargs)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/model/pairwise.py\", line 31, in get_scatter_plot\n",
      "    return scatter_pairwise(config, df_temp[x], df_temp[y], x, y)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/contextlib.py\", line 78, in inner\n",
      "    with self._recreate_cm():\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/visualisation/context.py\", line 83, in manage_matplotlib_context\n",
      "    deregister_matplotlib_converters()  # revert to original unit registries\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_misc.py\", line 151, in deregister\n",
      "    <AxesSubplot: xlabel='B', ylabel='C'>,\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_core.py\", line 1947, in _get_plot_backend\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_core.py\", line 1877, in _load_backend\n",
      "ImportError: matplotlib is required for plotting when the default backend \"matplotlib\" is selected.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data = {\"a\": list(range(0, 10)),\"b\": list(range(100, 200, 10))})\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(100, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1bae942ef54bf28081015adffc971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b3/g26r0dcx4b35vf3nk31216hc0000gr/T/ipykernel_10768/2135232660.py\", line 2, in <module>\n",
      "    profile.to_widgets()\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 516, in to_widgets\n",
      "    display(self.widgets)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 289, in widgets\n",
      "    isinstance(self.description_set.table[\"n\"], list)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 253, in description_set\n",
      "    self._description_set = describe_df(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/model/describe.py\", line 130, in describe\n",
      "    scatter_matrix[x][y] = progress(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/utils/progress_bar.py\", line 11, in inner\n",
      "    ret = fn(*args, **kwargs)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/model/pairwise.py\", line 31, in get_scatter_plot\n",
      "    return scatter_pairwise(config, df_temp[x], df_temp[y], x, y)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/contextlib.py\", line 78, in inner\n",
      "    with self._recreate_cm():\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/visualisation/context.py\", line 83, in manage_matplotlib_context\n",
      "    deregister_matplotlib_converters()  # revert to original unit registries\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_misc.py\", line 151, in deregister\n",
      "    <AxesSubplot: xlabel='B', ylabel='C'>,\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_core.py\", line 1947, in _get_plot_backend\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_core.py\", line 1877, in _load_backend\n",
      "ImportError: matplotlib is required for plotting when the default backend \"matplotlib\" is selected.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>target</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01020</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "      <td>Mask Off</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbone</td>\n",
       "      <td>Childish Gambino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03440</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>Xanny Family</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60400</td>\n",
       "      <td>0.494</td>\n",
       "      <td>199413</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>-15.236</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>86.468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1</td>\n",
       "      <td>Master Of None</td>\n",
       "      <td>Beach House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.678</td>\n",
       "      <td>392893</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-11.648</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>174.004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1</td>\n",
       "      <td>Parallel Lines</td>\n",
       "      <td>Junior Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.584</td>\n",
       "      <td>274404</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-3.501</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>74.976</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0</td>\n",
       "      <td>Like A Bitch - Kill The Noise Remix</td>\n",
       "      <td>Kill The Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.08770</td>\n",
       "      <td>0.894</td>\n",
       "      <td>182182</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>-2.663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>110.041</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0</td>\n",
       "      <td>Candy</td>\n",
       "      <td>Dillon Francis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.00857</td>\n",
       "      <td>0.637</td>\n",
       "      <td>207200</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>-2.467</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>150.082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0</td>\n",
       "      <td>Habit - Dack Janiels &amp; Wenzday Remix</td>\n",
       "      <td>Rain Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.557</td>\n",
       "      <td>185600</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>-2.735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>150.011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0</td>\n",
       "      <td>First Contact</td>\n",
       "      <td>Twin Moons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.446</td>\n",
       "      <td>204520</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>-6.221</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>190.013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0</td>\n",
       "      <td>I Wanna Get Better</td>\n",
       "      <td>Bleachers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0          0.01020         0.833       204600   0.434          0.021900    2   \n",
       "1          0.19900         0.743       326933   0.359          0.006110    1   \n",
       "2          0.03440         0.838       185707   0.412          0.000234    2   \n",
       "3          0.60400         0.494       199413   0.338          0.510000    5   \n",
       "4          0.18000         0.678       392893   0.561          0.512000    5   \n",
       "...            ...           ...          ...     ...               ...  ...   \n",
       "2012       0.00106         0.584       274404   0.932          0.002690    1   \n",
       "2013       0.08770         0.894       182182   0.892          0.001670    1   \n",
       "2014       0.00857         0.637       207200   0.935          0.003990    0   \n",
       "2015       0.00164         0.557       185600   0.992          0.677000    1   \n",
       "2016       0.00281         0.446       204520   0.915          0.000039    9   \n",
       "\n",
       "      liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n",
       "0       0.1650    -8.795     1       0.4310  150.062             4.0    0.286   \n",
       "1       0.1370   -10.401     1       0.0794  160.083             4.0    0.588   \n",
       "2       0.1590    -7.148     1       0.2890   75.044             4.0    0.173   \n",
       "3       0.0922   -15.236     1       0.0261   86.468             4.0    0.230   \n",
       "4       0.4390   -11.648     0       0.0694  174.004             4.0    0.904   \n",
       "...        ...       ...   ...          ...      ...             ...      ...   \n",
       "2012    0.1290    -3.501     1       0.3330   74.976             4.0    0.211   \n",
       "2013    0.0528    -2.663     1       0.1310  110.041             4.0    0.867   \n",
       "2014    0.2140    -2.467     1       0.1070  150.082             4.0    0.470   \n",
       "2015    0.0913    -2.735     1       0.1330  150.011             4.0    0.623   \n",
       "2016    0.2180    -6.221     1       0.1410  190.013             4.0    0.402   \n",
       "\n",
       "      target                            song_title            artist  \n",
       "0          1                              Mask Off            Future  \n",
       "1          1                               Redbone  Childish Gambino  \n",
       "2          1                          Xanny Family            Future  \n",
       "3          1                        Master Of None       Beach House  \n",
       "4          1                        Parallel Lines       Junior Boys  \n",
       "...      ...                                   ...               ...  \n",
       "2012       0   Like A Bitch - Kill The Noise Remix    Kill The Noise  \n",
       "2013       0                                 Candy    Dillon Francis  \n",
       "2014       0  Habit - Dack Janiels & Wenzday Remix          Rain Man  \n",
       "2015       0                         First Contact        Twin Moons  \n",
       "2016       0                    I Wanna Get Better         Bleachers  \n",
       "\n",
       "[2017 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629c09268d7a481e9b6a7b0439eda6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9469433f46a24bcd80c9c7847e50dc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b3/g26r0dcx4b35vf3nk31216hc0000gr/T/ipykernel_10768/3582944598.py\", line 7, in <module>\n",
      "    profile.to_file(\"output_report.html\")\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 355, in to_file\n",
      "    data = self.to_html()\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 470, in to_html\n",
      "    return self.html\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 277, in html\n",
      "    self._html = self._render_html()\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 385, in _render_html\n",
      "    report = self.report\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/profile_report.py\", line 271, in report\n",
      "    self._report = get_report_structure(self.config, self.description_set)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/report/structure/report.py\", line 387, in get_report_structure\n",
      "    render_variables_section(config, summary),\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/report/structure/report.py\", line 162, in render_variables_section\n",
      "    template_variables.update(render_map_type(config, template_variables))\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/report/structure/variables/render_real.py\", line 133, in render_real\n",
      "    mini_histogram(config, *summary[\"histogram\"]),\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/contextlib.py\", line 78, in inner\n",
      "    with self._recreate_cm():\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/ydata_profiling/visualisation/context.py\", line 83, in manage_matplotlib_context\n",
      "    deregister_matplotlib_converters()  # revert to original unit registries\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_misc.py\", line 151, in deregister\n",
      "    <AxesSubplot: xlabel='B', ylabel='C'>,\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_core.py\", line 1947, in _get_plot_backend\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/plotting/_core.py\", line 1877, in _load_backend\n",
      "ImportError: matplotlib is required for plotting when the default backend \"matplotlib\" is selected.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/kvarada/miniconda3/envs/cpsc330/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib \n",
    "\n",
    "# profile = ProfileReport(data, title=\"Pandas Profiling Report\")  # , minimal=True)\n",
    "profile = ProfileReport(data, title=\"Pandas Profiling Report\", minimal=True)\n",
    "profile.to_file(\"output_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature types \n",
    "\n",
    "- Do not blindly trust all the info given to you by automated tools. \n",
    "- How does pandas profiling figure out the data type?\n",
    "    - You can look at the Python data type and say floats are numeric, strings are categorical.\n",
    "    - However, in doing so you would miss out on various subtleties such as some of the string features being ordinal rather than truly categorical.\n",
    "    - Also, it will think free text is categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In addition to tools such as above, it's important to go through data description to understand the data.\n",
    "- The data description for our dataset is available [here](https://www.kaggle.com/c/home-data-for-ml-course/data?select=data_description.txt).     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature types \n",
    "\n",
    "- We have mixed feature types and a bunch of missing values. \n",
    "- Now, let's identify feature types and transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Let's get the numeric-looking columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_looking_columns = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "print(numeric_looking_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Not all numeric looking columns are necessarily numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"MSSubClass\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSSubClass: Identifies the type of dwelling involved in the sale.\t\n",
    "\n",
    "        20\t1-STORY 1946 & NEWER ALL STYLES\n",
    "        30\t1-STORY 1945 & OLDER\n",
    "        40\t1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45\t1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50\t1-1/2 STORY FINISHED ALL AGES\n",
    "        60\t2-STORY 1946 & NEWER\n",
    "        70\t2-STORY 1945 & OLDER\n",
    "        75\t2-1/2 STORY ALL AGES\n",
    "        80\tSPLIT OR MULTI-LEVEL\n",
    "        85\tSPLIT FOYER\n",
    "        90\tDUPLEX - ALL STYLES AND AGES\n",
    "       120\t1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150\t1-1/2 STORY PUD - ALL AGES\n",
    "       160\t2-STORY PUD - 1946 & NEWER\n",
    "       180\tPUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190\t2 FAMILY CONVERSION - ALL STYLES AND AGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Also, month sold is more of a categorical feature than a numeric feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"MoSold\"].unique()  # Month Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "drop_features = [\"Id\"]\n",
    "numeric_features = [\n",
    "    \"BedroomAbvGr\",\n",
    "    \"KitchenAbvGr\",\n",
    "    \"LotFrontage\",\n",
    "    \"LotArea\",\n",
    "    \"OverallQual\",\n",
    "    \"OverallCond\",\n",
    "    \"YearBuilt\",\n",
    "    \"YearRemodAdd\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"1stFlrSF\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"LowQualFinSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"FullBath\",\n",
    "    \"HalfBath\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"Fireplaces\",\n",
    "    \"GarageYrBlt\",\n",
    "    \"GarageCars\",\n",
    "    \"GarageArea\",\n",
    "    \"WoodDeckSF\",\n",
    "    \"OpenPorchSF\",\n",
    "    \"EnclosedPorch\",\n",
    "    \"3SsnPorch\",\n",
    "    \"ScreenPorch\",\n",
    "    \"PoolArea\",\n",
    "    \"MiscVal\",\n",
    "    \"YrSold\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{note}\n",
    "I've not looked at all the features carefully. It might be appropriate to apply some other encoding on some of the numeric features above. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "set(numeric_looking_columns) - set(numeric_features) - set(drop_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll treat the above numeric-looking features as categorical features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- There are a bunch of ordinal features in this dataset. \n",
    "- Ordinal features with the same scale \n",
    "    - Poor (Po), Fair (Fa), Typical (TA), Good (Gd), Excellent (Ex)\n",
    "    - These we'll be calling `ordinal_features_reg`.\n",
    "- Ordinal features with different scales\n",
    "    - These we'll be calling `ordinal_features_oth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_features_reg = [\n",
    "    \"ExterQual\",\n",
    "    \"ExterCond\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"HeatingQC\",\n",
    "    \"KitchenQual\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageQual\",\n",
    "    \"GarageCond\",\n",
    "    \"PoolQC\",\n",
    "]\n",
    "ordering = [\n",
    "    \"Po\",\n",
    "    \"Fa\",\n",
    "    \"TA\",\n",
    "    \"Gd\",\n",
    "    \"Ex\",\n",
    "]  # if N/A it will just impute something, per below\n",
    "ordering_ordinal_reg = [ordering] * len(ordinal_features_reg)\n",
    "ordering_ordinal_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pass the above as categories in our `OrdinalEncoder`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- There are a bunch more ordinal features using different scales.\n",
    "  - These we'll be calling `ordinal_features_oth`. \n",
    "  - We are encoding them separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features_oth = [\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtFinType1\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"Functional\",\n",
    "    \"Fence\",\n",
    "]\n",
    "ordering_ordinal_oth = [\n",
    "    [\"NA\", \"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    [\"Sal\", \"Sev\", \"Maj2\", \"Maj1\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    [\"NA\", \"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The remaining features are categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(\n",
    "    set(X_train.columns)\n",
    "    - set(numeric_features)\n",
    "    - set(ordinal_features_reg)\n",
    "    - set(ordinal_features_oth)\n",
    "    - set(drop_features)\n",
    ")\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- We are not doing it here but we can engineer our own features too. \n",
    "- Would price per square foot be a good feature to add in here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applying feature transformations\n",
    "\n",
    "- Since we have mixed feature types, let's use `ColumnTransformer` to apply different transformations on different features types.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "ordinal_transformer_reg = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OrdinalEncoder(categories=ordering_ordinal_reg),\n",
    ")\n",
    "\n",
    "ordinal_transformer_oth = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OrdinalEncoder(categories=ordering_ordinal_oth),\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (ordinal_transformer_reg, ordinal_features_reg),\n",
    "    (ordinal_transformer_oth, ordinal_features_oth),\n",
    "    (categorical_transformer, categorical_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examining the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)  # Calling fit to examine all the transformers.\n",
    "preprocessor.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ohe_columns = list(\n",
    "    preprocessor.named_transformers_[\"pipeline-4\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    ")\n",
    "new_columns = (\n",
    "    numeric_features + ordinal_features_reg + ordinal_features_oth + ohe_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X_train_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    ")\n",
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went from 80 features to 263 features!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other possible preprocessing?  \n",
    "\n",
    "- There is a lot of room for improvement ...\n",
    "- We're just using `SimpleImputer`.\n",
    "    - In reality we'd want to go through this more carefully.\n",
    "    - We may also want to drop some columns that are almost entirely missing.    \n",
    "- We could also check for outliers, and do other exploratory data analysis (EDA).\n",
    "- But for now this is good enough ...    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `DummyRegressor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor()\n",
    "pd.DataFrame(cross_validate(dummy, X_train, y_train, cv=10, return_train_score=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try a linear model: `Ridge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that we are going to use `Ridge()` instead of `LinearRegression()` in this course. \n",
    "- Similar to linear regression, ridge regression is also a linear model for regression. \n",
    "- So the formula it uses to make predictions is the same one used for ordinary least squares. \n",
    "- But it has a hyperparameter `alpha` which controls the fundamental tradeoff.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = make_pipeline(preprocessor, Ridge())\n",
    "lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr.predict(X_test)\n",
    "lr_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds.max(), lr_preds.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Smallest coefficient: \", lr.named_steps[\"ridge\"].coef_.min())\n",
    "print(\"Largest coefficient:\", lr.named_steps[\"ridge\"].coef_.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's carry out cross-validation with `Ridge`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(preprocessor, Ridge())\n",
    "pd.DataFrame(cross_validate(lr_pipe, X_train, y_train, cv=10, return_train_score=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quite a bit of variation in the test scores. \n",
    "- Performing poorly in fold 8. Not sure why. \n",
    "    - Probably it contains the outliers in the data which we kind of ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature names of transformed data\n",
    "\n",
    "- If you want to get the column names of newly created columns, you need to fit the transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = list(\n",
    "    preprocessor.named_transformers_[\"pipeline-4\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    ")\n",
    "ohe_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "new_columns = (\n",
    "    numeric_features + ordinal_features_reg + ordinal_features_oth + ohe_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tuning `alpha` hyperparameter of `Ridge`\n",
    "- Recall that `Ridge` has a hyperparameter `alpha` that controls the fundamental tradeoff.\n",
    "- This is like `C` in `LogisticRegression` but, annoyingly, `alpha` is the inverse of `C`.\n",
    "- That is, large `C` is like small `alpha` and vice versa.\n",
    "- Smaller `alpha`: lower training error (overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"ridge__alpha\": 10.0 ** np.arange(-5, 5, 1)}\n",
    "\n",
    "pipe_ridge = make_pipeline(preprocessor, Ridge())\n",
    "\n",
    "search = GridSearchCV(pipe_ridge, param_grid, return_train_score=True, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "train_scores = search.cv_results_[\"mean_train_score\"]\n",
    "cv_scores = search.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(param_grid[\"ridge__alpha\"], train_scores.tolist(), label=\"train\")\n",
    "plt.semilogx(param_grid[\"ridge__alpha\"], cv_scores.tolist(), label=\"cv\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"score\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "best_alpha = search.best_params_\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It seems alpha=100 is the best choice here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- General intuition: larger `alpha` leads to smaller coefficients.\n",
    "- Smaller coefficients mean the predictions are less sensitive to changes in the data. Hence less chance of overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bigalpha = make_pipeline(preprocessor, Ridge(alpha=1000))\n",
    "pipe_bigalpha.fit(X_train, y_train)\n",
    "bigalpha_coeffs = pipe_bigalpha.named_steps[\"ridge\"].coef_\n",
    "pd.DataFrame(\n",
    "    data=bigalpha_coeffs, index=new_columns, columns=[\"Coefficients\"]\n",
    ").sort_values(by=\"Coefficients\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Smaller `alpha` leads to bigger coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_smallalpha = make_pipeline(preprocessor, Ridge(alpha=0.01))\n",
    "pipe_smallalpha.fit(X_train, y_train)\n",
    "smallalpha_coeffs = pipe_smallalpha.named_steps[\"ridge\"].coef_\n",
    "pd.DataFrame(\n",
    "    data=smallalpha_coeffs, index=new_columns, columns=[\"Coefficients\"]\n",
    ").sort_values(by=\"Coefficients\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best alpha found by the grid search, the coefficients are somewhere in between. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bestalpha = make_pipeline(\n",
    "    preprocessor, Ridge(alpha=search.best_params_[\"ridge__alpha\"])\n",
    ")\n",
    "pipe_bestalpha.fit(X_train, y_train)\n",
    "bestalpha_coeffs = pipe_bestalpha.named_steps[\"ridge\"].coef_\n",
    "pd.DataFrame(\n",
    "    data=bestalpha_coeffs, index=new_columns, columns=[\"Coefficients\"]\n",
    ").sort_values(by=\"Coefficients\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize: \n",
    "- Higher values of `alpha` means a more restricted model.  \n",
    "- The values of coefficients are likely to be smaller for higher values of `alpha` compared to lower values of alpha. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `RidgeCV`\n",
    "\n",
    "Because it's so common to want to tune `alpha` with `Ridge`, sklearn provides a class called `RidgeCV`, which automatically tunes `alpha` based on cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10.0 ** np.arange(-6, 6, 1)\n",
    "ridgecv_pipe = make_pipeline(preprocessor, RidgeCV(alphas=alphas, cv=10))\n",
    "ridgecv_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = ridgecv_pipe.named_steps[\"ridgecv\"].alpha_\n",
    "\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_tuned = make_pipeline(preprocessor, Ridge(alpha=best_alpha))\n",
    "ridge_tuned.fit(X_train, y_train)\n",
    "ridge_preds = ridge_tuned.predict(X_test)\n",
    "ridge_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={\"coefficients\": ridge_tuned.named_steps[\"ridge\"].coef_}, index=new_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(\"coefficients\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So according to this model:\n",
    "\n",
    "- As `OverallQual` feature gets bigger the housing price will get bigger.\n",
    "- `Neighborhood_Edwards` is associated with reducing the housing price. \n",
    "    - We'll talk more about interpretation of different kinds of features next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_preds.max(), ridge_preds.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### iClicker Exercise 10.1\n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/SNBF**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) Price per square foot would be a good feature to add in our `X`. \n",
    "- (B) The `alpha` hyperparameter of `Ridge` has similar interpretation of `C` hyperparameter of `LogisticRegression`; higher `alpha` means more complex model. \n",
    "- (C) In `Ridge`, smaller alpha means bigger coefficients whereas bigger alpha means smaller coefficients.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we use the metrics we looked at in the previous lecture for this problem? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression scoring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- We aren't doing classification anymore, so we can't just check for equality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ridge_tuned.predict(X_train) == y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_tuned.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need a score that reflects how right/wrong each prediction is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "There are a number of popular scoring functions for regression. We are going to look at some common metrics: \n",
    "\n",
    "- mean squared error (MSE)\n",
    "- $R^2$\n",
    "- root mean squared error (RMSE)\n",
    "- MAPE\n",
    "\n",
    "See [sklearn documentation](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics) for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean squared error (MSE)\n",
    "\n",
    "- A common metric is mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preds = ridge_tuned.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.mean((y_train - preds) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Perfect predictions would have MSE=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_train - y_train) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is also implemented in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- MSE looks huge and unreasonable. There is an error of ~\\$1 Billion!\n",
    "- Is this score good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Unlike classification, with regression **our target has units**. \n",
    "- The target is in dollars, the mean squared error is in $dollars^2$ \n",
    "- The score also depends on the scale of the targets. \n",
    "- If we were working in cents instead of dollars, our MSE would be $10,000 \\times (100^2$) higher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_train * 100 - preds * 100) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error or RMSE\n",
    "\n",
    "- The MSE above is in $dollars^2$.\n",
    "- A more relatable metric would be the root mean squared error, or RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, ridge_tuned.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Error of \\$30,000 makes more sense.\n",
    "- Let's dig deeper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_train, ridge_tuned.predict(X_train), alpha=0.3)\n",
    "grid = np.linspace(y_train.min(), y_train.max(), 1000)\n",
    "plt.plot(grid, grid, \"--k\")\n",
    "plt.xlabel(\"true price\")\n",
    "plt.ylabel(\"predicted price\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Here we can see a few cases where our prediction is way off.\n",
    "- Is there something weird about those houses, perhaps? Outliers? \n",
    "- Under the line means we're under-predicting, over the line means we're over-predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $R^2$ (not in detail)\n",
    "\n",
    "A common score is the $R^2$\n",
    "\n",
    "- This is the score that `sklearn` uses by default when you call score()\n",
    "- You can [read about it](https://en.wikipedia.org/wiki/Coefficient_of_determination) if interested.\n",
    "- $R^2$ measures the proportion of variability in $y$ that can be explained using $X$. \n",
    "- Independent of the scale of $y$. So the max is 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^n (y_i - \\hat{y_i})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The denominator measures the total variance in $y$.  \n",
    "- The amount of variability that is left unexplained after performing regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Key points:\n",
    "- The maximum is 1 for perfect predictions\n",
    "- Negative values are very bad: \"worse than DummyRegressor\" (very bad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(Optional) Warning: MSE is \"reversible\" but $R^2$ is not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- When you call `fit` it minimizes MSE / maximizes $R^2$ (or something like that) by default.\n",
    "- Just like in classification, this isn't always what you want!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### MAPE\n",
    "\n",
    "- We got an RMSE of ~$30,000 before. \n",
    "\n",
    "Question: Is an error of \\$30,000 acceptable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, ridge_tuned.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- For a house worth \\$600k, it seems reasonable! That's 5% error.\n",
    "- For a house worth \\$60k, that is terrible. It's 50% error.\n",
    "\n",
    "We have both of these cases in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How about looking at percent error? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pred_train = ridge_tuned.predict(X_train)\n",
    "percent_errors = (pred_train - y_train) / y_train * 100.0\n",
    "percent_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are both positive (predict too high) and negative (predict too low)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can look at the absolute percent error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.abs(percent_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "And, like MSE, we can take the average over examples. This is called mean absolute percent error (MAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mape(true, pred):\n",
    "    return np.mean(np.abs((pred - true) / true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "my_mape(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `sklearn` to calculate MAPE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, this is quite interpretable.\n",
    "- On average, we have around 10% error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transforming the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- When you have prices or count data, the target values are skewed. \n",
    "- Let's look at our target column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common trick in such cases is applying a log transform on the target column to make it more normal and less skewed.  \n",
    "- That is, transform $y\\rightarrow \\log(y)$.\n",
    "- Linear regression will usually work better on something that looks more normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(np.log10(y_train), bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can incorporate this in our pipeline using `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ttr = TransformedTargetRegressor(\n",
    "    Ridge(alpha=best_alpha), func=np.log1p, inverse_func=np.expm1\n",
    ") # transformer for log transforming the target\n",
    "ttr_pipe = make_pipeline(preprocessor, ttr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why can't we incorporate preprocessing targets in our column transformer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ttr_pipe.fit(X_train, y_train); # y_train automatically transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ttr_pipe.predict(X_train)  # predictions automatically un-transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_train, ttr_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_test, ttr_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We reduced MAPE from ~10% to ~8% with this trick! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does `.fit()` know we care about MAPE?\n",
    "- No, it doesn't. Why are we minimizing MSE (or something similar) if we care about MAPE??\n",
    "- When minimizing MSE, the expensive houses will dominate because they have the biggest error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Different scoring functions with `cross_validate`\n",
    "\n",
    "- Let's try using MSE instead of the default $R^2$ score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    cross_validate(\n",
    "        ridge_tuned,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        return_train_score=True,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(my_mape, greater_is_better=False)\n",
    "\n",
    "pd.DataFrame(\n",
    "    cross_validate(\n",
    "        ridge_tuned, X_train, y_train, return_train_score=True, scoring=mape_scorer\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are finding `greater_is_better=False` argument confusing, here is the documentation: \n",
    "\n",
    "> greater_is_better(bool), default=True\n",
    "Whether score_func is a score function (default), meaning high is good, or a loss function, meaning low is good. In the latter case, the scorer object will sign-flip the outcome of the score_func.\n",
    "\n",
    "Since our custom scorer `mape` gives an error and not a score, I'm passing `False` to it and it'll sign flip so that we can interpret bigger numbers as better performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer, # just for demonstration for a custom scorer\n",
    "    \"sklearn MAPE\": \"neg_mean_absolute_percentage_error\",\n",
    "    \"neg_root_mean_square_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "}\n",
    "\n",
    "pd.DataFrame(\n",
    "    cross_validate(\n",
    "        ridge_tuned, X_train, y_train, return_train_score=True, scoring=scoring\n",
    "    )\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we getting the same `alpha` with mape? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"ridge__alpha\": 10.0 ** np.arange(-6, 6, 1)}\n",
    "\n",
    "pipe_ridge = make_pipeline(preprocessor, Ridge())\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe_ridge, param_grid, return_train_score=True, n_jobs=-1, scoring=mape_scorer\n",
    ")\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameter values: \", search.best_params_)\n",
    "print(\"Best score: %0.3f\" % (search.best_score_))\n",
    "pd.DataFrame(search.cv_results_)[\n",
    "    [\n",
    "        \"mean_train_score\",\n",
    "        \"mean_test_score\",\n",
    "        \"param_ridge__alpha\",\n",
    "        \"mean_fit_time\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using multiple metrics in `GridSearchCV` or `RandomizedSearchCV` \n",
    "\n",
    "- We could use multiple metrics with `GridSearchCV` or `RandomizedSearchCV`. \n",
    "- But if you do so, you need to set `refit` to the metric (string) for which the `best_params_` will be found and used to build the `best_estimator_` on the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_multi = GridSearchCV(\n",
    "    pipe_ridge,\n",
    "    param_grid,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=scoring,\n",
    "    refit=\"sklearn MAPE\",\n",
    ")\n",
    "search_multi.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameter values: \", search_multi.best_params_)\n",
    "print(\"Best score: %0.3f\" % (search_multi.best_score_))\n",
    "pd.DataFrame(search_multi.cv_results_).set_index(\"rank_test_mape_scorer\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the test score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_multi.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mape(y_test, ridge_tuned.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using regression metrics with `scikit-learn`\n",
    "\n",
    "- In `sklearn`, you will notice that it has negative version of the metrics above (e.g., `neg_mean_squared_error`, `neg_root_mean_squared_error`). \n",
    "- The reason for this is that scores return a value to maximize, the higher the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ❓❓ Questions for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iClicker Exercise 10.2\n",
    "\n",
    "**iClicker cloud join link: https://join.iclicker.com/SNBF**\n",
    "\n",
    "**Select all of the following statements which are TRUE.**\n",
    "\n",
    "- (A) We can use still use precision and recall for regression problems but now we have other metrics we can use as well.\n",
    "- (B) In `sklearn` for regression problems, using `r2_score()` and `.score()` (with default values) will produce the same results.\n",
    "- (C) RMSE is always going to be non-negative.\n",
    "- (D) MSE does not directly provide the information about whether the model is underpredicting or overpredicting.\n",
    "- (E) We can pass multiple scoring metrics to `GridSearchCV` or `RandomizedSearchCV` for regression as well as classification problems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What did we learn today? \n",
    "\n",
    "- House prices dataset target is price, which is numeric -> regression rather than classification\n",
    "- There are corresponding versions of all the tools we used:\n",
    "    - `DummyClassifier` -> `DummyRegressor`\n",
    "    - `LogisticRegression` -> `Ridge`\n",
    "- `Ridge` hyperparameter `alpha` is like `LogisticRegression` hyperparameter `C`, but opposite meaning\n",
    "- We'll avoid `LinearRegression` in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Scoring metrics\n",
    "- $R^2$ is the default .score(), it is unitless, 0 is bad, 1 is best\n",
    "- MSE (mean squared error) is in units of target squared, hard to interpret; 0 is best\n",
    "- RMSE (root mean squared error) is in the same units as the target; 0 is best\n",
    "- MAPE (mean absolute percent error) is unitless; 0 is best, 1 is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-seeyou.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "cpsc330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
